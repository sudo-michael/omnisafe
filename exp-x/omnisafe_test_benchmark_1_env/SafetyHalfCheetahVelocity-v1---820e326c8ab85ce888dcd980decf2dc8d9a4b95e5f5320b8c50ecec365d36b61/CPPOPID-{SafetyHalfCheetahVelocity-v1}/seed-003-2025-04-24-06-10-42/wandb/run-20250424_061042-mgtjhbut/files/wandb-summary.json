{"Loss/Loss_cost_critic":0.5883001685142517,"Loss/Loss_reward_critic/Delta":-3.0344486236572266,"Loss/Loss_reward_critic":11.637596130371094,"Train/KL":0.009196826256811619,"Value/Adv":-0.18334557116031647,"Metrics/EpLen":1000,"Train/LR":0,"Loss/Loss_cost_critic/Delta":-0.041274189949035645,"Loss/Loss_pi":-0.0077318111434578896,"Time/FPS":75.81698608398438,"_step":50,"Loss/Loss_pi/Delta":0.0012590093538165092,"Train/PolicyStd":0.3767775595188141,"Value/cost":4.8072943687438965,"Time/Epoch":263.7931213378906,"Metrics/EpRet":1212.5899658203125,"Value/reward":112.68569946289062,"_runtime":10995.770322856,"Train/PolicyRatio/Min":1.0002461671829224,"_timestamp":1.7455112378979228e+09,"Train/PolicyRatio":1.0002461671829224,"Train/PolicyRatio/Max":1.0002461671829224,"Train/PolicyRatio/Std":0.016170816496014595,"Metrics/LagrangeMultiplier":1.702314019203186,"Train/Entropy":0.42338696122169495,"Time/Total":10994.9833984375,"Metrics/EpCost":56.56999969482422,"_wandb":{"runtime":10995},"Time/Rollout":123.32784271240234,"Time/Update":140.46522521972656,"Train/Epoch":49,"Train/StopIter":40,"TotalEnvSteps":1e+06}