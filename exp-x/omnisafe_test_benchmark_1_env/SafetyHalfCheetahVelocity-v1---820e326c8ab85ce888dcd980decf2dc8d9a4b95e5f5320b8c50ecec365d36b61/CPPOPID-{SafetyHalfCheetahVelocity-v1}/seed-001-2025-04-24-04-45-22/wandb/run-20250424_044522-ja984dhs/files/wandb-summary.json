{"Metrics/EpCost":67.69999694824219,"Train/PolicyStd":0.43850868940353394,"Train/LR":0,"Value/cost":5.001466274261475,"Metrics/EpLen":1000,"Loss/Loss_reward_critic":34.43540573120117,"Value/Adv":-0.052053652703762054,"TotalEnvSteps":1e+06,"Loss/Loss_pi":-0.011577949859201908,"Time/Total":11393.7294921875,"Time/Epoch":274.3747253417969,"Time/FPS":72.89301300048828,"Train/Entropy":0.5826377272605896,"Metrics/LagrangeMultiplier":2.0600550174713135,"Loss/Loss_cost_critic/Delta":-0.23955631256103516,"_wandb":{"runtime":11394},"Loss/Loss_reward_critic/Delta":-4.503059387207031,"Loss/Loss_cost_critic":1.6404757499694824,"Train/KL":0.009107683785259724,"Train/PolicyRatio":0.9996684789657593,"Value/reward":134.3512725830078,"_timestamp":1.7455065165751672e+09,"Train/PolicyRatio/Min":0.9996684789657593,"Train/PolicyRatio/Max":0.9996684789657593,"Loss/Loss_pi/Delta":0.0001616068184375763,"Metrics/EpRet":1482.426513671875,"Time/Rollout":122.59061431884766,"_step":50,"Time/Update":151.78404235839844,"Train/PolicyRatio/Std":0.015560546889901161,"_runtime":11394.504610025,"Train/StopIter":40,"Train/Epoch":49}