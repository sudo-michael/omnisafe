{"Loss/Loss_pi/Delta":0.04352695168927312,"Train/Epoch":49,"Time/Update":4.18986701965332,"Train/LR":0,"Loss/Loss_reward_critic":8.9508695602417,"Loss/Loss_pi":0.036906976252794266,"_wandb":{"runtime":8293},"_step":50,"_timestamp":1.7455108908467731e+09,"Train/KL":0.1178269162774086,"Metrics/EpRet":1090.92822265625,"Value/Adv":0.22787439823150635,"Train/Entropy":0.3981849253177643,"Metrics/EpLen":1000,"Time/FPS":158.09210205078125,"Metrics/EpCost":27.790000915527344,"Time/Rollout":122.31856536865234,"Time/Total":8292.58203125,"Loss/Loss_pi_cost":55.49300003051758,"Loss/Loss_cost_critic":0.34745100140571594,"Value/cost":1.8901691436767578,"Time/Epoch":126.50853729248047,"Train/PolicyRatio/Std":0.04175260663032532,"_runtime":8293.321228299,"Loss/Loss_cost_critic/Delta":0.01573464274406433,"Train/PolicyStd":0.367706298828125,"Value/reward":100.53074645996094,"Loss/Loss_reward_critic/Delta":0.04846477508544922,"Train/PolicyRatio/Min":1.0011154413223267,"Loss/Loss_pi_cost/Delta":55.49300003051758,"Train/StopIter":1,"Train/PolicyRatio":1.0011154413223267,"Train/PolicyRatio/Max":1.0011154413223267,"TotalEnvSteps":1e+06}