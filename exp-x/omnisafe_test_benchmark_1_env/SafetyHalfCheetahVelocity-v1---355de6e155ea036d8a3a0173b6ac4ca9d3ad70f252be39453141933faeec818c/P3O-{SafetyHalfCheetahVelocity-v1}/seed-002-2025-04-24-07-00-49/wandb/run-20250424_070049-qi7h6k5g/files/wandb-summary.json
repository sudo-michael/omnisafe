{"Loss/Loss_cost_critic/Delta":-0.3968017101287842,"Train/PolicyRatio/Min":0.999871015548706,"Train/KL":0.02705979533493519,"Loss/Loss_reward_critic/Delta":-5.045574188232422,"_wandb":{"runtime":8381},"_timestamp":1.7455116310473554e+09,"Time/Epoch":133.4132843017578,"Train/LR":0,"Loss/Loss_pi_cost":84.25838470458984,"Value/reward":123.43892669677734,"Train/PolicyRatio":0.999871015548706,"Train/StopIter":2,"Metrics/EpRet":1382.521240234375,"TotalEnvSteps":1e+06,"Train/PolicyStd":0.476656049489975,"Loss/Loss_cost_critic":0.5951862931251526,"Time/FPS":149.91012573242188,"Loss/Loss_pi/Delta":-0.02174470853060484,"Time/Rollout":123.64738464355469,"Loss/Loss_reward_critic":44.49784469604492,"Train/PolicyRatio/Max":0.999871015548706,"Metrics/EpLen":1000,"Metrics/EpCost":29.219999313354492,"Value/cost":2.075408697128296,"Time/Total":8381.177734375,"Loss/Loss_pi":0.014462449587881565,"Train/Entropy":0.6690862774848938,"_step":50,"Train/PolicyRatio/Std":0.017786163836717606,"Time/Update":9.76582145690918,"Train/Epoch":49,"_runtime":8381.903684685,"Loss/Loss_pi_cost/Delta":18.36163330078125,"Value/Adv":0.009063847362995148}