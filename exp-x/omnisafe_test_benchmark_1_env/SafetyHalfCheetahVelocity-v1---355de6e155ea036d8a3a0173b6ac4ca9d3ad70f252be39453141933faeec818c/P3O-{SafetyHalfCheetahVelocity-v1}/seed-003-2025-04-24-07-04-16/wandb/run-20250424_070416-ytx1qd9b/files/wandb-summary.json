{"Time/Update":45.01939010620117,"Train/KL":0.004886262584477663,"Loss/Loss_reward_critic":32.40730285644531,"Loss/Loss_reward_critic/Delta":-0.025928497314453125,"Value/cost":0.3935547471046448,"Time/FPS":117.64208221435547,"Time/Epoch":170.00718688964844,"Train/Epoch":49,"_step":50,"Train/StopIter":10,"Loss/Loss_pi/Delta":0.0018452159129083157,"_wandb":{"runtime":8298},"_runtime":8298.666551337,"Metrics/EpLen":1000,"Train/PolicyRatio/Max":0.9997578859329224,"Loss/Loss_cost_critic":0.06514260917901993,"Loss/Loss_pi_cost":0,"Train/PolicyRatio/Min":0.9997578859329224,"Loss/Loss_pi":-0.005937316920608282,"Metrics/EpRet":1040.2384033203125,"Value/Adv":0.014237195253372192,"Train/PolicyStd":0.4487951397895813,"Time/Rollout":124.98772430419922,"Train/LR":0,"Value/reward":98.5661849975586,"Time/Total":8297.8818359375,"Train/Entropy":0.6108954548835754,"Train/PolicyRatio":0.9997578859329224,"Loss/Loss_cost_critic/Delta":-0.018429838120937347,"Train/PolicyRatio/Std":0.011146027594804764,"TotalEnvSteps":1e+06,"Metrics/EpCost":2.75,"Loss/Loss_pi_cost/Delta":0,"_timestamp":1.7455117549706068e+09}