{"Train/Entropy":0.5725011229515076,"Metrics/EpCost":1.059999942779541,"Loss/Loss_pi/Delta":0.0058892276138067245,"Metrics/LagrangeMultiplier":0,"Time/Total":10328.2587890625,"Time/Update":137.2353515625,"Train/KL":0.007846048101782799,"Train/Epoch":49,"Metrics/EpLen":81.5199966430664,"Metrics/EpRet":22.94280242919922,"Train/PolicyStd":0.42897164821624756,"_wandb":{"runtime":10329},"_step":50,"Time/FPS":76.30517578125,"Train/PolicyRatio":1.0006591081619263,"Time/Epoch":262.10540771484375,"Train/PolicyRatio/Min":1.0006591081619263,"Train/StopIter":40,"Loss/Loss_cost_critic":0.5378794074058533,"Value/Adv":0.16087964177131653,"Value/reward":-1.5855170488357544,"Loss/Loss_cost_critic/Delta":-0.18771058320999146,"Train/PolicyRatio/Max":1.0006591081619263,"Train/PolicyRatio/Std":0.013530743308365345,"_runtime":10329.129750067,"_timestamp":1.7454613555500424e+09,"Value/cost":0.43836510181427,"Loss/Loss_pi":-0.0161636620759964,"Loss/Loss_reward_critic":26.917211532592773,"Train/LR":0,"Loss/Loss_reward_critic/Delta":-4.939460754394531,"TotalEnvSteps":1e+06,"Time/Rollout":124.86998748779297}