{"_runtime":10502.355897973,"Train/KL":0.007955826818943024,"TotalEnvSteps":1e+06,"Time/FPS":75.4511947631836,"Train/PolicyRatio":0.9986386895179749,"Metrics/EpCost":2.009999990463257,"_timestamp":1.7454510255821717e+09,"Value/cost":0.8120231628417969,"Loss/Loss_pi":-0.016432849690318108,"Metrics/LagrangeMultiplier":0,"Train/PolicyRatio/Max":0.9986386299133301,"Train/PolicyStd":0.4265861213207245,"Loss/Loss_pi/Delta":0.006331155076622963,"Loss/Loss_cost_critic/Delta":0.1982162594795227,"Value/reward":2.755187511444092,"Train/Entropy":0.5668066740036011,"Loss/Loss_reward_critic/Delta":5.56048583984375,"Train/Epoch":49,"Time/Epoch":265.0719909667969,"Time/Update":142.16941833496094,"Train/PolicyRatio/Min":0.9986386299133301,"Metrics/EpLen":71.0999984741211,"_step":50,"Train/LR":0,"Train/StopIter":40,"Time/Rollout":122.90251159667969,"_wandb":{"runtime":10502},"Train/PolicyRatio/Std":0.013828335329890251,"Value/Adv":-0.20505082607269287,"Time/Total":10501.5615234375,"Loss/Loss_reward_critic":40.7607421875,"Metrics/EpRet":27.12567710876465,"Loss/Loss_cost_critic":0.9977719783782959}