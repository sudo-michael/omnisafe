{"Loss/Loss_pi/Delta":0.006633581593632698,"Train/StopIter":40,"Loss/Loss_pi":-0.016046296805143356,"Value/Adv":-0.09607051312923431,"Time/Rollout":124.14301300048828,"_runtime":10483.31859654,"Loss/Loss_reward_critic/Delta":9.47899055480957,"Metrics/EpLen":87.80000305175781,"TotalEnvSteps":1e+06,"Time/Update":142.49095153808594,"Train/PolicyRatio/Min":1.0001084804534912,"Metrics/EpRet":24.697561264038086,"Time/Total":10482.4404296875,"Time/FPS":75.0091781616211,"Metrics/EpCost":1.7799999713897705,"Train/PolicyRatio/Std":0.013136131688952446,"Train/PolicyRatio":1.0001084804534912,"Train/PolicyStd":0.424358606338501,"Value/reward":0.8740689158439636,"Train/LR":0,"Metrics/LagrangeMultiplier":0,"Loss/Loss_cost_critic/Delta":0.09645593166351318,"_wandb":{"runtime":10483},"Time/Epoch":266.634033203125,"Train/PolicyRatio/Max":1.0001084804534912,"Train/KL":0.007511927746236324,"Train/Epoch":49,"Loss/Loss_cost_critic":0.7264396548271179,"_step":50,"Train/Entropy":0.5614497065544128,"Value/cost":0.528016984462738,"_timestamp":1.7454510066695583e+09,"Loss/Loss_reward_critic":35.92476272583008}