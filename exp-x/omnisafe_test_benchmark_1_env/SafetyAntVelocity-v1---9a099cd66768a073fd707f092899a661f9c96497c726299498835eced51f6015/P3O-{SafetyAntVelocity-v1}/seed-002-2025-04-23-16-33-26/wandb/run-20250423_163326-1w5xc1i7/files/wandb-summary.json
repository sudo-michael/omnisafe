{"Train/PolicyRatio/Max":1.0001230239868164,"TotalEnvSteps":1e+06,"Train/PolicyRatio":1.000123143196106,"Loss/Loss_reward_critic/Delta":9.132274627685547,"Train/Epoch":49,"Time/Update":49.30891418457031,"_step":50,"Time/Epoch":204.3166961669922,"Metrics/EpRet":92.95860290527344,"Value/reward":18.678071975708008,"Train/LR":0,"Value/Adv":-0.15197446942329407,"Value/cost":0.6817941665649414,"Train/PolicyRatio/Std":0.008108556270599365,"Time/Rollout":155.0076904296875,"Metrics/EpLen":194.0500030517578,"Train/PolicyRatio/Min":1.0001230239868164,"_runtime":8634.529816652,"Train/KL":0.004200515802949667,"Train/StopIter":10,"Loss/Loss_pi/Delta":0.00226845545694232,"Metrics/EpCost":2.549999952316284,"Train/Entropy":0.4962729215621948,"_wandb":{"runtime":8634},"_timestamp":1.7454598414049098e+09,"Loss/Loss_pi_cost/Delta":0,"Loss/Loss_reward_critic":53.06901550292969,"Loss/Loss_cost_critic":0.536362886428833,"Loss/Loss_cost_critic/Delta":0.011423468589782715,"Train/PolicyStd":0.39749810099601746,"Loss/Loss_pi":-0.005298073403537273,"Time/FPS":97.88725280761719,"Loss/Loss_pi_cost":0,"Time/Total":8633.7900390625}