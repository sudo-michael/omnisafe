{"Train/StopIter":10,"Loss/Loss_pi/Delta":0.0031918403692543507,"Time/Update":50.976287841796875,"Time/FPS":98.88630676269531,"Time/Epoch":202.25247192382812,"Train/PolicyRatio":1.0005571842193604,"Metrics/EpLen":120.5199966430664,"Metrics/EpCost":2.0799999237060547,"Train/PolicyRatio/Min":1.0005571842193604,"TotalEnvSteps":1e+06,"Value/reward":12.315755844116211,"Loss/Loss_pi_cost/Delta":0,"Train/Epoch":49,"Loss/Loss_pi":-0.00430880393832922,"_timestamp":1.7454596624878497e+09,"Time/Rollout":151.2760772705078,"Train/PolicyRatio/Std":0.007729330565780401,"Loss/Loss_reward_critic":51.24790954589844,"Train/KL":0.003916371613740921,"Loss/Loss_pi_cost":0,"Train/PolicyRatio/Max":1.0005571842193604,"Train/Entropy":0.5286067724227905,"Metrics/EpRet":45.3942756652832,"_runtime":8627.283353614,"Loss/Loss_cost_critic":0.6893438696861267,"Value/cost":0.6613684296607971,"Time/Total":8626.486328125,"Value/Adv":0.45558440685272217,"Loss/Loss_reward_critic/Delta":12.400012969970703,"_step":50,"Loss/Loss_cost_critic/Delta":0.01377791166305542,"Train/PolicyStd":0.4105890691280365,"_wandb":{"runtime":8627},"Train/LR":0}