{"Train/Epoch":49,"Time/Total":8600.529296875,"Value/Adv":-0.1616791933774948,"Train/PolicyRatio/Min":0.999518871307373,"_runtime":8601.285315614,"Time/Update":45.306514739990234,"Train/KL":0.003982072696089745,"Value/reward":14.977334022521973,"Metrics/EpLen":169.0800018310547,"Metrics/EpCost":2.069999933242798,"Value/cost":0.5908494591712952,"Time/FPS":99.9462661743164,"Loss/Loss_pi_cost/Delta":0,"Train/Entropy":0.5181462168693542,"_wandb":{"runtime":8601},"TotalEnvSteps":1e+06,"_step":50,"Loss/Loss_pi/Delta":0.002565896138548851,"Loss/Loss_pi_cost":0,"Loss/Loss_cost_critic":0.6348456740379333,"Train/PolicyRatio/Max":0.999518871307373,"Train/StopIter":10,"Metrics/EpRet":65.58728790283203,"Train/LR":0,"_timestamp":1.7454598731973324e+09,"Train/PolicyRatio/Std":0.007258810102939606,"Loss/Loss_pi":-0.004810946993529797,"Train/PolicyStd":0.40636810660362244,"Train/PolicyRatio":0.999518871307373,"Time/Epoch":200.10752868652344,"Loss/Loss_reward_critic/Delta":3.261371612548828,"Loss/Loss_reward_critic":49.33892822265625,"Time/Rollout":154.8009490966797,"Loss/Loss_cost_critic/Delta":0.08842098712921143}