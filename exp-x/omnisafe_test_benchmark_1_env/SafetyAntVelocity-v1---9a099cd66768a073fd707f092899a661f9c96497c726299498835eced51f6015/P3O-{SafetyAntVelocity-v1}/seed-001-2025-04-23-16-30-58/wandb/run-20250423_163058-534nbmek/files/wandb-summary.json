{"Time/Total":8327.025390625,"_timestamp":1.7454593859022374e+09,"Train/StopIter":10,"Time/FPS":118.76383209228516,"Time/Rollout":126.53229522705078,"_step":50,"Loss/Loss_pi":-0.004125368315726519,"Train/PolicyRatio":0.9999887943267822,"Train/PolicyRatio/Max":0.9999887347221375,"Metrics/EpLen":164.44000244140625,"Loss/Loss_cost_critic":0.33234405517578125,"Train/LR":0,"Loss/Loss_reward_critic/Delta":8.122573852539062,"Loss/Loss_pi_cost/Delta":0,"Loss/Loss_pi_cost":0,"_wandb":{"runtime":8327},"Train/PolicyRatio/Min":0.9999887347221375,"Train/Entropy":0.5080778002738953,"Loss/Loss_pi/Delta":0.0023607774637639523,"TotalEnvSteps":1e+06,"Time/Update":41.869083404541016,"Time/Epoch":168.4014434814453,"Train/PolicyStd":0.40233588218688965,"Metrics/EpCost":1.1799999475479126,"Value/cost":0.4539276361465454,"_runtime":8327.849737097,"Value/reward":18.199565887451172,"Value/Adv":-0.031681306660175323,"Train/PolicyRatio/Std":0.007663065567612648,"Loss/Loss_cost_critic/Delta":-0.07102406024932861,"Train/Epoch":49,"Train/KL":0.00414036400616169,"Loss/Loss_reward_critic":54.34902572631836,"Metrics/EpRet":69.79444885253906}