{"Metrics/EpCost":4.699999809265137,"Train/PolicyRatio":0.999554455280304,"Train/PolicyStd":0.6799586415290833,"Train/PolicyRatio/Std":0.01619085483253002,"Train/PolicyRatio/Min":0.999554455280304,"Metrics/EpLen":1000,"Value/cost":0.28558266162872314,"Train/PolicyRatio/Max":0.999554455280304,"Loss/Loss_cost_critic/Delta":0.02191491425037384,"Loss/Loss_reward_critic/Delta":0.009714752435684204,"Train/Entropy":1.030267357826233,"TotalEnvSteps":1e+06,"Value/reward":114.17682647705078,"Loss/Loss_pi_cost/Delta":0,"_step":50,"Train/LR":0,"_timestamp":1.7454897733540213e+09,"Train/StopIter":10,"Value/Adv":-0.12168946862220764,"Metrics/EpRet":1156.8824462890625,"Time/Rollout":150.39215087890625,"Loss/Loss_pi":-0.018278902396559715,"Loss/Loss_pi_cost":0,"_wandb":{"runtime":8465},"Train/KL":0.009628121741116047,"Time/Update":51.558929443359375,"Loss/Loss_cost_critic":0.11183539032936096,"Loss/Loss_pi/Delta":0.00112152099609375,"Train/Epoch":49,"_runtime":8465.257130948,"Time/FPS":99.03385925292969,"Loss/Loss_reward_critic":0.48067620396614075,"Time/Total":8464.423828125,"Time/Epoch":201.95114135742188}