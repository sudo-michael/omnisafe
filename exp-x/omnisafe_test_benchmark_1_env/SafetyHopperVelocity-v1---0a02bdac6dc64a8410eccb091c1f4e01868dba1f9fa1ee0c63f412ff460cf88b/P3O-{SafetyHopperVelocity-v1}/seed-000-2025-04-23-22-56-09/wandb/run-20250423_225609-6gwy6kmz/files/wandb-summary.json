{"Train/LR":0,"_step":50,"Train/StopIter":10,"Time/Epoch":231.35841369628906,"Train/PolicyRatio/Min":0.9999520778656006,"Metrics/EpCost":1.4600000381469727,"TotalEnvSteps":1e+06,"Metrics/EpRet":1041.408447265625,"Loss/Loss_pi/Delta":0.0010656998492777348,"Metrics/EpLen":979.5700073242188,"Value/cost":0.10537370294332504,"Loss/Loss_cost_critic":0.09747055172920227,"Loss/Loss_reward_critic/Delta":-0.7462055683135986,"_runtime":8433.08972103,"Train/PolicyRatio/Std":0.012797967530786991,"Train/PolicyRatio":0.9999521374702454,"Loss/Loss_pi_cost":0,"Train/PolicyRatio/Max":0.9999520778656006,"Value/reward":102.78044128417969,"Time/Update":55.51336669921875,"Train/PolicyStd":0.7043026685714722,"Loss/Loss_cost_critic/Delta":-0.012899734079837799,"Loss/Loss_pi_cost/Delta":0,"_wandb":{"runtime":8433},"Train/KL":0.00793833751231432,"Loss/Loss_pi":-0.0027081386651843786,"Time/FPS":86.44596099853516,"_timestamp":1.7454826025749056e+09,"Time/Total":8432.3388671875,"Train/Epoch":49,"Train/Entropy":1.0654098987579346,"Loss/Loss_reward_critic":3.589484930038452,"Time/Rollout":175.844970703125,"Value/Adv":0.04030630365014076}