{"Train/PolicyRatio/Std":0.015835879370570183,"_runtime":8344.82670808,"Time/Rollout":125.0936508178711,"Loss/Loss_pi/Delta":0.0015501957386732101,"Time/Update":46.095645904541016,"TotalEnvSteps":1e+06,"Loss/Loss_pi_cost":0,"Loss/Loss_cost_critic/Delta":-0.01598457433283329,"Loss/Loss_reward_critic":17.254423141479492,"Loss/Loss_cost_critic":0.02419370226562023,"_step":50,"Train/PolicyRatio":0.9994826912879944,"Time/Epoch":171.18939208984375,"Value/Adv":-0.11142192780971527,"Train/LR":0,"_timestamp":1.7454904337608953e+09,"Loss/Loss_pi_cost/Delta":0,"Value/reward":98.43272399902344,"Metrics/EpRet":821.243896484375,"Train/PolicyStd":0.6179782748222351,"Train/Epoch":49,"Time/FPS":116.82967376708984,"Train/PolicyRatio/Max":0.9994826912879944,"Loss/Loss_reward_critic/Delta":-54.93268013000488,"Train/PolicyRatio/Min":0.9994826912879944,"Time/Total":8343.841796875,"Metrics/EpCost":0.6600000262260437,"_wandb":{"runtime":8344},"Metrics/EpLen":794.719970703125,"Train/KL":0.00877310335636139,"Train/StopIter":10,"Loss/Loss_pi":-0.006000256631523371,"Value/cost":0.04921811446547508,"Train/Entropy":0.9192189574241638}