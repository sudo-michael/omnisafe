{"Time/FPS":149.04185485839844,"Loss/Loss_cost_critic/Delta":0.0647861510786285,"Metrics/EpLen":966.010009765625,"Train/PolicyRatio/Max":1.000293254852295,"Train/StopIter":10,"Loss/Loss_pi_cost":0,"Value/cost":-0.007686588913202286,"_step":50,"Value/Adv":-0.2097346931695938,"TotalEnvSteps":1e+06,"Train/PolicyStd":0.5742332935333252,"_wandb":{"runtime":7737},"Value/reward":94.35450744628906,"Loss/Loss_pi_cost/Delta":0,"Time/Update":40.300907135009766,"Time/Epoch":134.19049072265625,"Train/PolicyRatio/Std":0.013547496870160103,"Train/PolicyRatio/Min":1.000293254852295,"Loss/Loss_pi/Delta":0.022543651517480612,"_timestamp":1.7454820880749485e+09,"Loss/Loss_reward_critic/Delta":25.630300015211105,"Loss/Loss_reward_critic":25.9331111907959,"Metrics/EpRet":974.3182983398438,"Train/PolicyRatio":1.000293254852295,"Time/Total":7736.98095703125,"_runtime":7737.825818009,"Train/LR":0,"Loss/Loss_pi":-0.004325945395976305,"Train/KL":0.006565150339156389,"Loss/Loss_cost_critic":0.06478623300790787,"Time/Rollout":93.88951873779297,"Metrics/EpCost":0.20000000298023224,"Train/Epoch":49,"Train/Entropy":0.8599255084991455}