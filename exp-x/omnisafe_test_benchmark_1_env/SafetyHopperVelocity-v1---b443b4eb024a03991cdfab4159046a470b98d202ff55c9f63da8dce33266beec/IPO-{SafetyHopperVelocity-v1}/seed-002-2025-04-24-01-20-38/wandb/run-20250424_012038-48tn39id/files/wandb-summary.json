{"TotalEnvSteps":1e+06,"Time/FPS":103.33451080322266,"Train/PolicyRatio/Std":0.018387021496891975,"Metrics/EpLen":68.93000030517578,"Loss/Loss_cost_critic/Delta":-9.962890625,"Train/PolicyStd":0.7424258589744568,"Train/Epoch":49,"Time/Total":9317.060546875,"Loss/Loss_reward_critic":76.8605728149414,"Time/Update":37.83528518676758,"Time/Rollout":155.71083068847656,"Train/LR":0,"Value/reward":21.32271957397461,"Train/Entropy":1.120753526687622,"Train/PolicyRatio":1.0013530254364014,"Loss/Loss_reward_critic/Delta":-27.373146057128906,"Train/PolicyRatio/Min":1.0013530254364014,"Train/KL":0.01197265088558197,"_step":50,"_runtime":9317.803830809,"Metrics/EpRet":140.74932861328125,"Value/Adv":-0.05997642129659653,"Train/PolicyRatio/Max":1.0013530254364014,"Metrics/EpCost":29.989999771118164,"Misc/Penalty":1,"_wandb":{"runtime":9317},"Loss/Loss_cost_critic":46.37990188598633,"Train/StopIter":10,"Value/cost":9.442815780639648,"_timestamp":1.7454921561446133e+09,"Time/Epoch":193.54617309570312,"Loss/Loss_pi":-0.07313129305839539,"Loss/Loss_pi/Delta":-0.05299343541264534}