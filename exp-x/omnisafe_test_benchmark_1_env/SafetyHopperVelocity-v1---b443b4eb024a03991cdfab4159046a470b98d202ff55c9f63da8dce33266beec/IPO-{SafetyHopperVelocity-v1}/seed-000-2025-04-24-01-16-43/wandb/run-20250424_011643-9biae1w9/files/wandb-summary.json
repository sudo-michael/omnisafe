{"Loss/Loss_reward_critic/Delta":13.863285064697266,"Loss/Loss_cost_critic":25.85822105407715,"Metrics/EpLen":54.119998931884766,"Train/Epoch":49,"Loss/Loss_reward_critic":57.83229446411133,"Metrics/EpCost":13.369999885559082,"Train/PolicyRatio/Min":1.0014461278915405,"Time/Rollout":154.9993133544922,"Train/PolicyRatio/Max":1.0014461278915405,"Train/KL":0.012243270874023438,"Misc/Penalty":0.0008598451968282461,"Time/Epoch":192.16786193847656,"Time/Update":37.1684684753418,"Metrics/EpRet":99.5027084350586,"_step":50,"Loss/Loss_pi":-0.024959929287433624,"Train/StopIter":10,"Value/cost":6.471851348876953,"TotalEnvSteps":1e+06,"Train/PolicyStd":0.7186256647109985,"Train/PolicyRatio/Std":0.017510956153273582,"Time/FPS":104.07567596435547,"Train/PolicyRatio":1.0014461278915405,"Loss/Loss_cost_critic/Delta":2.6745033264160156,"_timestamp":1.745491813713794e+09,"Time/Total":9209.1259765625,"_wandb":{"runtime":9210},"_runtime":9210.277033847,"Train/LR":0,"Value/reward":17.947887420654297,"Loss/Loss_pi/Delta":0.022275574505329132,"Value/Adv":-0.08836670219898224,"Train/Entropy":1.0875184535980225}