{"Value/Adv":-0.021683894097805023,"Value/reward":18.695344924926758,"Train/Epoch":49,"Train/StopIter":10,"Train/LR":0,"Value/cost":7.2657670974731445,"_timestamp":1.745495173594394e+09,"Misc/Penalty":0.0013054829323664308,"Time/Epoch":199.45291137695312,"Metrics/EpRet":120.5633316040039,"Loss/Loss_pi/Delta":0.022828493267297745,"Time/FPS":100.27429962158203,"Train/PolicyRatio/Min":1.0016276836395264,"_wandb":{"runtime":9806},"Loss/Loss_pi":-0.02142384648323059,"Train/Entropy":1.0658613443374634,"Time/Rollout":157.16151428222656,"Time/Update":42.29132080078125,"Time/Total":9805.2236328125,"TotalEnvSteps":1e+06,"Loss/Loss_cost_critic/Delta":2.58258056640625,"Train/PolicyStd":0.7031573057174683,"Train/PolicyRatio/Max":1.0016276836395264,"Metrics/EpCost":17.34000015258789,"Train/PolicyRatio":1.0016276836395264,"Metrics/EpLen":63.36000061035156,"Train/PolicyRatio/Std":0.016324490308761597,"Loss/Loss_reward_critic":46.1083984375,"Loss/Loss_reward_critic/Delta":7.455821990966797,"_step":50,"Loss/Loss_cost_critic":24.922861099243164,"_runtime":9806.170978759,"Train/KL":0.01133169885724783}