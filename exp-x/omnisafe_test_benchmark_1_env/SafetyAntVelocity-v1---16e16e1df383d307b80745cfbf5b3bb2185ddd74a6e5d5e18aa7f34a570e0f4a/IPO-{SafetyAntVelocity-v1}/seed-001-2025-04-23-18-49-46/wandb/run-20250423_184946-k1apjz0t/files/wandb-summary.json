{"Loss/Loss_pi/Delta":0.00185673451051116,"Train/PolicyRatio":1.0000298023223877,"Metrics/EpRet":591.2694702148438,"Time/Update":42.550559997558594,"_runtime":10025.091283389,"Loss/Loss_reward_critic/Delta":9.787747383117676,"Value/reward":71.03630828857422,"Metrics/EpLen":878.8200073242188,"Train/LR":0,"Train/Entropy":0.3268319368362427,"Time/FPS":86.94361877441406,"Value/Adv":0.07296238094568253,"Value/cost":-4.711948394775391,"Time/Total":10024.40234375,"TotalEnvSteps":1e+06,"Train/PolicyStd":0.33571696281433105,"Train/Epoch":49,"Loss/Loss_cost_critic/Delta":0.08354763686656952,"_step":50,"Train/PolicyRatio/Std":0.007861722260713577,"Misc/Penalty":0.0004046944377478212,"Metrics/EpCost":0.28999999165534973,"_timestamp":1.7454694119323773e+09,"Time/Rollout":187.4835205078125,"Train/KL":0.004105426836758852,"Time/Epoch":230.0341339111328,"Loss/Loss_cost_critic":0.22741052508354187,"Train/PolicyRatio/Min":1.0000298023223877,"Loss/Loss_reward_critic":25.01626968383789,"_wandb":{"runtime":10025},"Loss/Loss_pi":-0.004197809379547834,"Train/StopIter":10,"Train/PolicyRatio/Max":1.0000298023223877}