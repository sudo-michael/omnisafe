{"Loss/Loss_pi/Delta":0.002764069940894842,"Train/Epoch":49,"TotalEnvSteps":1e+06,"_timestamp":1.745460771186024e+09,"Train/PolicyRatio/Min":1.0001380443572998,"Loss/Loss_reward_critic":26.965166091918945,"Train/PolicyRatio/Std":0.006607326213270426,"Loss/Loss_cost_critic/Delta":-0.06842634081840515,"Train/PolicyRatio":1.0001380443572998,"Value/reward":70.51249694824219,"Train/Entropy":0.3379083275794983,"Value/Adv":-0.07340365648269653,"Time/Rollout":154.2494659423828,"Time/Total":9419.2236328125,"_step":50,"Loss/Loss_cost_critic":0.2591153681278229,"Time/Epoch":194.4148712158203,"Time/Update":40.16535186767578,"Metrics/EpLen":809.1900024414062,"Train/LR":0,"Misc/Penalty":0.0004076640761923045,"Loss/Loss_pi":-0.003949005156755447,"Train/StopIter":10,"Loss/Loss_reward_critic/Delta":-0.14028358459472656,"Train/PolicyRatio/Max":1.0001380443572998,"Time/FPS":102.87278747558594,"Metrics/EpRet":531.6498413085938,"Metrics/EpCost":0.4699999988079071,"_runtime":9419.944229376,"_wandb":{"runtime":9419},"Train/PolicyStd":0.33944153785705566,"Value/cost":-4.642381191253662,"Train/KL":0.003298019990324974}