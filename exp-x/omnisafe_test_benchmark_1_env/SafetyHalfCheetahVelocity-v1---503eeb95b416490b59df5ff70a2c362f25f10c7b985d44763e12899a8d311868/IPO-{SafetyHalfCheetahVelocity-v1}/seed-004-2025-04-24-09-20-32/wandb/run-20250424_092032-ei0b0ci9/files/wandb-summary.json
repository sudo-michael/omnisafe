{"Loss/Loss_cost_critic/Delta":-4.195840835571289,"Train/Epoch":49,"Time/Total":6597.88037109375,"Value/cost":4.413619518280029,"Train/StopIter":10,"Train/PolicyRatio":0.999672532081604,"Metrics/EpRet":1436.2314453125,"TotalEnvSteps":1e+06,"Time/Epoch":91.16332244873047,"Loss/Loss_reward_critic/Delta":-5.586093902587891,"Train/PolicyRatio/Min":0.999672532081604,"Time/Rollout":59.03081512451172,"Train/PolicyRatio/Max":0.999672532081604,"Time/FPS":219.386474609375,"Train/PolicyRatio/Std":0.01085439883172512,"Loss/Loss_reward_critic":40.62684631347656,"Train/LR":0,"Metrics/EpCost":25.610000610351562,"Train/KL":0.005720099434256554,"Loss/Loss_cost_critic":24.173192977905273,"Train/PolicyStd":0.44153326749801636,"_runtime":6598.680326966,"Train/Entropy":0.595762312412262,"Loss/Loss_pi/Delta":0.008565890602767467,"_wandb":{"runtime":6598},"Misc/Penalty":1,"Value/Adv":-0.37183257937431335,"Time/Update":32.132389068603516,"Loss/Loss_pi":-0.011772382073104382,"_step":50,"_timestamp":1.7455182307205868e+09,"Value/reward":100.75624084472656,"Metrics/EpLen":1000}