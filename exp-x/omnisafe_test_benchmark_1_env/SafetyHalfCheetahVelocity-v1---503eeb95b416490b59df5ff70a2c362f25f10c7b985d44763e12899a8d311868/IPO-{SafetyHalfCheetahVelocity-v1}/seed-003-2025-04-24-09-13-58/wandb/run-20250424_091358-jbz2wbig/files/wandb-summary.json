{"Train/PolicyRatio/Min":0.9984742999076843,"Time/FPS":215.51377868652344,"Value/reward":82.29557800292969,"Train/PolicyStd":0.47168079018592834,"Loss/Loss_reward_critic/Delta":3.874500274658203,"_wandb":{"runtime":6573},"Loss/Loss_reward_critic":54.30691909790039,"Time/Epoch":92.8014907836914,"_timestamp":1.7455178124131794e+09,"Train/Epoch":49,"Loss/Loss_pi":-0.017420049756765366,"Train/PolicyRatio/Max":0.9984742999076843,"Loss/Loss_pi/Delta":-0.011217605322599411,"Time/Rollout":62.03345489501953,"_step":50,"Metrics/EpLen":1000,"Misc/Penalty":1,"Value/cost":2.2822835445404053,"TotalEnvSteps":1e+06,"Value/Adv":0.07174190878868103,"Metrics/EpRet":1310.1142578125,"Time/Update":30.76797866821289,"Train/LR":0,"Time/Total":6572.86474609375,"Loss/Loss_cost_critic":24.871074676513672,"_runtime":6573.596020478,"Metrics/EpCost":25.579999923706055,"Train/KL":0.005692823324352503,"Train/PolicyRatio/Std":0.01205629762262106,"Train/Entropy":0.6618947386741638,"Train/StopIter":10,"Train/PolicyRatio":0.9984742999076843,"Loss/Loss_cost_critic/Delta":-2.53363037109375}