{"Train/PolicyRatio":0.9995908141136169,"Metrics/LagrangeMultiplier/Max":0.8275408744812012,"Train/PolicyRatio/Max":0.9995908141136169,"_wandb":{"runtime":12638},"Time/Rollout":123.661865234375,"Train/Epoch":49,"Train/PolicyRatio/Min":0.9995908141136169,"Time/Update":137.94627380371094,"TotalEnvSteps":1e+06,"_runtime":12638.326857729,"Metrics/LagrangeMultiplier/Std":0,"Loss/Loss_cost_critic":2.014824628829956,"Train/PolicyStd":0.476328045129776,"Value/cost":0.90720134973526,"Loss/Loss_pi/Delta":0.0011092355707660317,"Train/PolicyRatio/Std":0.014157946221530437,"Train/LR":0,"Metrics/LagrangeMultiplier/Min":0.8275408744812012,"Train/StopIter":40,"_step":50,"Loss/Loss_reward_critic/Delta":8.834031105041504,"Time/Epoch":261.6081848144531,"Value/Adv":0.2311505228281021,"Loss/Loss_cost_critic/Delta":1.0541077256202698,"Metrics/LagrangeMultiplier":0.8275408744812012,"Train/KL":0.007960929535329342,"Loss/Loss_pi":-0.0019482908537611365,"Metrics/EpCost":1.9500000476837158,"Time/Total":12637.3916015625,"Value/reward":35.79098892211914,"Train/Entropy":0.6721896529197693,"_timestamp":1.745474349265567e+09,"Metrics/EpRet":83.89682006835938,"Time/FPS":76.45020294189453,"Metrics/EpLen":53.2400016784668,"Loss/Loss_reward_critic":17.39029884338379}