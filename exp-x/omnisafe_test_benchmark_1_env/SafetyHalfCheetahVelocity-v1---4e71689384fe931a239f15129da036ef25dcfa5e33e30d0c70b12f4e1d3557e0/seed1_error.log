wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in ./exp-x/omnisafe_test_benchmark_1_env/SafetyHalfCheetahVelocity-v1---4e71689384fe931a239f15129da036ef25dcfa5e33e30d0c70b12f4e1d3557e0/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-001-2025-04-24-03-16-14/wandb/run-20250424_031614-duqrqlft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-001-2025-04-24-03-16-14
wandb: â­ï¸ View project at https://wandb.ai/mlu/omnisafe
wandb: ğŸš€ View run at https://wandb.ai/mlu/omnisafe/runs/duqrqlft
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          Loss/Loss_cost_critic â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–ˆ
wandb:    Loss/Loss_cost_critic/Delta â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–‡â–‡â–â–…â–ˆ
wandb:                   Loss/Loss_pi â–‡â–†â–…â–„â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–ˆ
wandb:             Loss/Loss_pi/Delta â–â–†â–†â–…â–…â–‡â–‡â–†â–‡â–†â–‡â–‡â–…â–‡â–†â–‡â–‡â–†â–†â–†â–‡â–…â–‡â–†â–‡â–‡â–…â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:        Loss/Loss_reward_critic â–„â–„â–†â–„â–„â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–…â–…â–…â–…â–…â–…â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:  Loss/Loss_reward_critic/Delta â–ˆâ–ƒâ–„â–â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–„â–„â–ƒâ–ƒ
wandb:                 Metrics/EpCost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–†â–†â–ˆ
wandb:                  Metrics/EpLen â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  Metrics/EpRet â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:     Metrics/LagrangeMultiplier â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb: Metrics/LagrangeMultiplier/Max â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb: Metrics/LagrangeMultiplier/Min â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb: Metrics/LagrangeMultiplier/Std â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                     Time/Epoch â–‡â–ˆâ–‡â–ˆâ–‡â–„â–„â–ƒâ–‚â–â–‚â–â–ƒâ–â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–„â–†â–†â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       Time/FPS â–â–â–‚â–â–‚â–„â–„â–…â–†â–ˆâ–‡â–‡â–†â–‡â–…â–†â–‡â–ˆâ–†â–…â–‡â–†â–†â–…â–…â–„â–…â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:                   Time/Rollout â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:                     Time/Total â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    Time/Update â–‡â–ˆâ–‡â–ˆâ–‡â–„â–„â–ƒâ–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–„â–†â–†â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                  TotalEnvSteps â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                  Train/Entropy â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                    Train/Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       Train/KL â–„â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–…â–†â–…â–„â–„â–„â–ƒâ–ƒâ–
wandb:                       Train/LR â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:              Train/PolicyRatio â–ˆâ–‡â–„â–„â–‡â–†â–†â–ƒâ–ˆâ–„â–ˆâ–…â–†â–…â–ƒâ–ƒâ–…â–ƒâ–„â–…â–…â–…â–…â–†â–†â–…â–‡â–‡â–â–â–…â–„â–†â–‚â–„â–†â–…â–…â–„â–ˆ
wandb:          Train/PolicyRatio/Max â–ˆâ–‡â–„â–„â–‡â–†â–†â–ˆâ–„â–‚â–…â–†â–…â–ƒâ–†â–…â–„â–…â–ƒâ–…â–…â–†â–†â–‡â–„â–‡â–‡â–â–ƒâ–â–…â–„â–†â–‚â–„â–†â–…â–…â–„â–ˆ
wandb:          Train/PolicyRatio/Min â–ˆâ–‡â–„â–„â–‡â–†â–†â–ƒâ–ˆâ–„â–ˆâ–…â–†â–…â–ƒâ–ƒâ–…â–ƒâ–„â–…â–…â–…â–…â–†â–‡â–‡â–‡â–â–ƒâ–â–…â–„â–†â–‚â–„â–†â–…â–…â–„â–ˆ
wandb:          Train/PolicyRatio/Std â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–„â–ƒâ–
wandb:                Train/PolicyStd â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:                 Train/StopIter â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–†â–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      Value/Adv â–ƒâ–…â–…â–„â–„â–„â–…â–…â–ˆâ–„â–ƒâ–ƒâ–‚â–†â–†â–…â–†â–‚â–â–„â–‡â–…â–„â–„â–„â–‚â–„â–„â–„â–„â–…â–„â–„â–„â–„â–‚â–„â–…â–†â–…
wandb:                     Value/cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:                   Value/reward â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:          Loss/Loss_cost_critic 2.78263
wandb:    Loss/Loss_cost_critic/Delta 0.47603
wandb:                   Loss/Loss_pi -0.01247
wandb:             Loss/Loss_pi/Delta 0.00491
wandb:        Loss/Loss_reward_critic 40.10272
wandb:  Loss/Loss_reward_critic/Delta 2.03308
wandb:                 Metrics/EpCost 81.98
wandb:                  Metrics/EpLen 1000
wandb:                  Metrics/EpRet 1522.61182
wandb:     Metrics/LagrangeMultiplier 0.03057
wandb: Metrics/LagrangeMultiplier/Max 0.03057
wandb: Metrics/LagrangeMultiplier/Min 0.03057
wandb: Metrics/LagrangeMultiplier/Std 0
wandb:                     Time/Epoch 266.07562
wandb:                       Time/FPS 75.1666
wandb:                   Time/Rollout 121.97134
wandb:                     Time/Total 11069.24805
wandb:                    Time/Update 144.10422
wandb:                  TotalEnvSteps 1000000.0
wandb:                  Train/Entropy 0.55903
wandb:                    Train/Epoch 49
wandb:                       Train/KL 0.00706
wandb:                       Train/LR 0
wandb:              Train/PolicyRatio 1.00107
wandb:          Train/PolicyRatio/Max 1.00107
wandb:          Train/PolicyRatio/Min 1.00107
wandb:          Train/PolicyRatio/Std 0.01288
wandb:                Train/PolicyStd 0.42835
wandb:                 Train/StopIter 40
wandb:                      Value/Adv 0.04492
wandb:                     Value/cost 5.92311
wandb:                   Value/reward 141.84912
wandb: 
wandb: ğŸš€ View run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-001-2025-04-24-03-16-14 at: https://wandb.ai/mlu/omnisafe/runs/duqrqlft
wandb: â­ï¸ View project at: https://wandb.ai/mlu/omnisafe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./exp-x/omnisafe_test_benchmark_1_env/SafetyHalfCheetahVelocity-v1---4e71689384fe931a239f15129da036ef25dcfa5e33e30d0c70b12f4e1d3557e0/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-001-2025-04-24-03-16-14/wandb/run-20250424_031614-duqrqlft/logs
