wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in ./exp-x/omnisafe_test_benchmark_1_env/SafetyHalfCheetahVelocity-v1---4e71689384fe931a239f15129da036ef25dcfa5e33e30d0c70b12f4e1d3557e0/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-000-2025-04-24-03-02-50/wandb/run-20250424_030250-pre8o8mc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-000-2025-04-24-03-02-50
wandb: â­ï¸ View project at https://wandb.ai/mlu/omnisafe
wandb: ğŸš€ View run at https://wandb.ai/mlu/omnisafe/runs/pre8o8mc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          Loss/Loss_cost_critic â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–„â–…â–„â–†â–ˆ
wandb:    Loss/Loss_cost_critic/Delta â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–„â–„â–ƒâ–†â–…â–â–ˆâ–…
wandb:                   Loss/Loss_pi â–ˆâ–†â–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–â–â–â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–„â–‡
wandb:             Loss/Loss_pi/Delta â–â–„â–…â–…â–…â–‡â–‡â–†â–…â–‡â–†â–‡â–‡â–…â–‡â–ˆâ–†â–‡â–…â–†â–‡â–†â–†â–‡â–…â–ˆâ–…â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–ˆ
wandb:        Loss/Loss_reward_critic â–…â–ˆâ–‡â–„â–†â–…â–„â–ƒâ–ƒâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–„
wandb:  Loss/Loss_reward_critic/Delta â–ˆâ–…â–â–„â–‚â–‚â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„
wandb:                 Metrics/EpCost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–ˆ
wandb:                  Metrics/EpLen â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  Metrics/EpRet â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     Metrics/LagrangeMultiplier â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Metrics/LagrangeMultiplier/Max â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Metrics/LagrangeMultiplier/Min â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Metrics/LagrangeMultiplier/Std â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                     Time/Epoch â–ˆâ–ˆâ–ˆâ–…â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:                       Time/FPS â–â–â–â–ƒâ–‚â–„â–…â–†â–†â–ˆâ–‡â–…â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–…â–„â–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                   Time/Rollout â–ˆâ–ˆâ–ˆâ–â–â–‚â–â–â–‚â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚
wandb:                     Time/Total â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:                    Time/Update â–ˆâ–ˆâ–ˆâ–†â–‡â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                  TotalEnvSteps â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                  Train/Entropy â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                    Train/Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       Train/KL â–„â–„â–…â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–†â–†â–…â–„â–„â–„â–ƒâ–
wandb:                       Train/LR â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:              Train/PolicyRatio â–†â–†â–†â–„â–†â–†â–„â–†â–…â–…â–ˆâ–„â–†â–†â–„â–…â–…â–ƒâ–ƒâ–†â–â–…â–†â–…â–…â–…â–„â–„â–ƒâ–‡â–ƒâ–†â–‡â–„â–„â–…â–†â–†â–†â–†
wandb:          Train/PolicyRatio/Max â–†â–…â–ƒâ–…â–…â–ƒâ–†â–„â–…â–…â–‚â–ˆâ–†â–†â–‚â–…â–â–â–†â–…â–„â–†â–…â–„â–‡â–ƒâ–ƒâ–‚â–ˆâ–†â–…â–‡â–‚â–ƒâ–ˆâ–„â–†â–†â–†â–†
wandb:          Train/PolicyRatio/Min â–‡â–‡â–†â–…â–†â–†â–„â–†â–†â–†â–„â–ˆâ–‡â–†â–„â–…â–†â–ƒâ–ƒâ–‡â–â–…â–‡â–†â–…â–†â–…â–„â–„â–ˆâ–†â–ˆâ–„â–…â–ˆâ–…â–‡â–‡â–‡â–‡
wandb:          Train/PolicyRatio/Std â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–„â–ƒâ–
wandb:                Train/PolicyStd â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:                 Train/StopIter â–ˆâ–ˆâ–†â–ˆâ–†â–„â–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–…â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      Value/Adv â–ˆâ–†â–…â–†â–…â–†â–…â–‡â–„â–…â–…â–„â–†â–„â–†â–ƒâ–ˆâ–†â–…â–‡â–„â–†â–†â–â–†â–†â–ƒâ–…â–†â–„â–†â–„â–„â–†â–…â–†â–†â–‡â–ˆâ–ƒ
wandb:                     Value/cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–‡â–ˆ
wandb:                   Value/reward â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:          Loss/Loss_cost_critic 0.14099
wandb:    Loss/Loss_cost_critic/Delta 0.01799
wandb:                   Loss/Loss_pi -0.0148
wandb:             Loss/Loss_pi/Delta 0.00379
wandb:        Loss/Loss_reward_critic 16.53849
wandb:  Loss/Loss_reward_critic/Delta 3.29122
wandb:                 Metrics/EpCost 7.84
wandb:                  Metrics/EpLen 1000
wandb:                  Metrics/EpRet 1107.18213
wandb:     Metrics/LagrangeMultiplier 0
wandb: Metrics/LagrangeMultiplier/Max 0
wandb: Metrics/LagrangeMultiplier/Min 0
wandb: Metrics/LagrangeMultiplier/Std 0
wandb:                     Time/Epoch 269.00607
wandb:                       Time/FPS 74.34776
wandb:                   Time/Rollout 124.53287
wandb:                     Time/Total 11270.18652
wandb:                    Time/Update 144.47313
wandb:                  TotalEnvSteps 1000000.0
wandb:                  Train/Entropy 0.45184
wandb:                    Train/Epoch 49
wandb:                       Train/KL 0.00734
wandb:                       Train/LR 0
wandb:              Train/PolicyRatio 1.00064
wandb:          Train/PolicyRatio/Max 1.00064
wandb:          Train/PolicyRatio/Min 1.00064
wandb:          Train/PolicyRatio/Std 0.01291
wandb:                Train/PolicyStd 0.38697
wandb:                 Train/StopIter 40
wandb:                      Value/Adv -0.24544
wandb:                     Value/cost 0.55809
wandb:                   Value/reward 101.15384
wandb: 
wandb: ğŸš€ View run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-000-2025-04-24-03-02-50 at: https://wandb.ai/mlu/omnisafe/runs/pre8o8mc
wandb: â­ï¸ View project at: https://wandb.ai/mlu/omnisafe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./exp-x/omnisafe_test_benchmark_1_env/SafetyHalfCheetahVelocity-v1---4e71689384fe931a239f15129da036ef25dcfa5e33e30d0c70b12f4e1d3557e0/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-000-2025-04-24-03-02-50/wandb/run-20250424_030250-pre8o8mc/logs
