{"_runtime":10534.471359226,"_step":50,"Train/PolicyRatio/Min":0.9991713762283325,"Time/Update":136.23422241210938,"Metrics/LagrangeMultiplier/Max":0,"Time/Total":10533.59375,"Train/PolicyStd":0.4323286712169647,"Value/cost":0.6241732239723206,"Metrics/EpCost":1.4600000381469727,"Train/LR":0,"Metrics/EpRet":19.702674865722656,"_timestamp":1.7454510571805937e+09,"Time/FPS":76.77304077148438,"Metrics/LagrangeMultiplier/Std":0,"TotalEnvSteps":1e+06,"Train/Epoch":49,"Loss/Loss_pi/Delta":0.005167234688997269,"Train/PolicyRatio/Max":0.9991713762283325,"Loss/Loss_pi":-0.016712050884962082,"Train/Entropy":0.5800985097885132,"Value/reward":-1.9660706520080566,"Loss/Loss_reward_critic":33.47041702270508,"Metrics/LagrangeMultiplier":0,"Value/Adv":0.032098427414894104,"Time/Epoch":260.50811767578125,"_wandb":{"runtime":10534},"Metrics/LagrangeMultiplier/Min":0,"Metrics/EpLen":80.51000213623047,"Loss/Loss_cost_critic/Delta":-0.25363290309906006,"Train/PolicyRatio":0.9991713762283325,"Loss/Loss_reward_critic/Delta":-10.443317413330078,"Train/PolicyRatio/Std":0.013742556795477867,"Time/Rollout":124.27383422851562,"Train/StopIter":40,"Loss/Loss_cost_critic":0.7085943818092346,"Train/KL":0.007769835647195578}