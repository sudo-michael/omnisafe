{"Value/cost":0.5824503898620605,"Metrics/EpRet":18.10879898071289,"Loss/Loss_reward_critic":29.534194946289062,"Train/PolicyRatio":0.9992049932479858,"_wandb":{"runtime":10510},"Time/Total":10510.1259765625,"Train/PolicyRatio/Std":0.01296963170170784,"Metrics/LagrangeMultiplier/Max":0,"Loss/Loss_cost_critic/Delta":-0.06279981136322021,"Loss/Loss_reward_critic/Delta":3.156984329223633,"Train/LR":0,"Train/PolicyStd":0.4307980537414551,"Metrics/LagrangeMultiplier":0,"_step":50,"Train/PolicyRatio/Max":0.9992049932479858,"Time/Update":140.3235321044922,"_runtime":10510.983344284,"Time/FPS":75.98931121826172,"Loss/Loss_cost_critic":0.8476632833480835,"Train/StopIter":40,"Time/Epoch":263.1949157714844,"Train/Entropy":0.5766991972923279,"Loss/Loss_pi":-0.01641727052628994,"Value/Adv":0.2444176971912384,"Time/Rollout":122.8713150024414,"Train/KL":0.007549863774329424,"Metrics/LagrangeMultiplier/Min":0,"Loss/Loss_pi/Delta":0.00573221780359745,"Metrics/LagrangeMultiplier/Std":0,"Metrics/EpCost":1.5800000429153442,"Train/PolicyRatio/Min":0.9992049932479858,"Value/reward":-3.8060109615325928,"TotalEnvSteps":1e+06,"_timestamp":1.7454510339782271e+09,"Train/Epoch":49,"Metrics/EpLen":87.18000030517578}