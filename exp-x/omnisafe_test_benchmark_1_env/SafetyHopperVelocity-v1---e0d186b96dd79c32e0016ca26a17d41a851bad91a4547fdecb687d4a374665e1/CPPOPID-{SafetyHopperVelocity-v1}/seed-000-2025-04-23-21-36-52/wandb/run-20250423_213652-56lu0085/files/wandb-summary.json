{"Train/PolicyRatio/Max":1.0008361339569092,"_step":50,"Train/PolicyRatio/Min":1.0008361339569092,"Metrics/LagrangeMultiplier":1.383496642112732,"Loss/Loss_reward_critic/Delta":-0.05198991298675537,"Loss/Loss_cost_critic/Delta":0.013629361987113953,"Loss/Loss_cost_critic":0.023992124944925308,"Loss/Loss_reward_critic":0.8319270610809326,"Train/Epoch":49,"Loss/Loss_pi/Delta":-0.000871412456035614,"_wandb":{"runtime":11894},"Loss/Loss_pi":-0.006875935941934586,"Train/PolicyRatio/Std":0.016209369525313377,"Train/Entropy":0.8596117496490479,"_runtime":11894.55723191,"Train/StopIter":40,"Time/Epoch":267.5556945800781,"Train/KL":0.009321196004748344,"Time/Update":143.85055541992188,"Value/cost":0.41537413001060486,"Metrics/EpRet":1229.7242431640625,"Value/reward":120.92867279052734,"Train/PolicyStd":0.5735037326812744,"Time/Total":11893.7666015625,"Metrics/EpCost":1.5099999904632568,"Time/Rollout":123.705078125,"_timestamp":1.7454813072972171e+09,"Value/Adv":-0.1983380913734436,"Train/PolicyRatio":1.0008361339569092,"Train/LR":0,"Time/FPS":74.75079345703125,"Metrics/EpLen":992.5700073242188,"TotalEnvSteps":1e+06}