{"Time/FPS":89.07740020751953,"Train/LR":0,"Value/cost":0.9775696992874146,"Metrics/EpRet":1197.09033203125,"_timestamp":1.7454817086061938e+09,"Time/Update":129.44610595703125,"Value/reward":121.21634674072266,"Loss/Loss_pi":-0.003421774599701166,"Metrics/LagrangeMultiplier":0.6525153517723083,"Train/PolicyRatio/Std":0.012988975271582603,"_runtime":12033.719741291,"Time/Total":12032.9462890625,"Loss/Loss_cost_critic/Delta":-0.0828905701637268,"Time/Epoch":224.52383422851562,"Loss/Loss_reward_critic/Delta":0.6572135090827942,"Loss/Loss_reward_critic":1.6417325735092163,"Train/StopIter":40,"_wandb":{"runtime":12033},"Loss/Loss_pi/Delta":0.0013138656504452229,"Train/PolicyRatio":0.9993196725845337,"Train/PolicyRatio/Min":0.9993196725845337,"Metrics/EpLen":963.5499877929688,"Train/Entropy":0.8421059250831604,"TotalEnvSteps":1e+06,"_step":50,"Train/KL":0.0067931790836155415,"Time/Rollout":95.0776596069336,"Loss/Loss_cost_critic":0.16103985905647278,"Train/Epoch":49,"Train/PolicyStd":0.5648896098136902,"Value/Adv":0.0158192478120327,"Metrics/EpCost":4.110000133514404,"Train/PolicyRatio/Max":0.9993196725845337}