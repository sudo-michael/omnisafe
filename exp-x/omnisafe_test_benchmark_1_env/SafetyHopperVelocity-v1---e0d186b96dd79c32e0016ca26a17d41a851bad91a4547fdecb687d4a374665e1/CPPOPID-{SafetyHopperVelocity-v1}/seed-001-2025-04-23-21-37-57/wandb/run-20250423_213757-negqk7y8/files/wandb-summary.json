{"Time/Update":148.27496337890625,"Train/LR":0,"Metrics/EpLen":969.7000122070312,"Train/PolicyRatio/Min":0.9992714524269104,"Loss/Loss_reward_critic":0.9955023527145386,"Train/PolicyStd":0.5298697352409363,"Metrics/LagrangeMultiplier":0.32446983456611633,"TotalEnvSteps":1e+06,"Time/Epoch":316.17059326171875,"Train/StopIter":40,"Time/Total":13359.671875,"_runtime":13360.41032206,"Time/FPS":63.256988525390625,"Loss/Loss_cost_critic":0.37968653440475464,"Metrics/EpRet":1468.4200439453125,"Loss/Loss_pi/Delta":-0.0022057127207517624,"Train/PolicyRatio/Std":0.01468358188867569,"Metrics/EpCost":9.3100004196167,"Value/Adv":-0.06767357140779495,"Train/Epoch":49,"Loss/Loss_pi":-0.006369923707097769,"Value/cost":1.5260835886001587,"_wandb":{"runtime":13360},"_step":50,"Loss/Loss_reward_critic/Delta":-17.575943112373352,"Train/KL":0.007725676521658897,"Train/PolicyRatio/Max":0.9992714524269104,"Loss/Loss_cost_critic/Delta":0.21250823140144348,"Train/Entropy":0.782224714756012,"Train/PolicyRatio":0.9992714524269104,"_timestamp":1.745482837515118e+09,"Value/reward":148.7252197265625,"Time/Rollout":167.8955841064453}