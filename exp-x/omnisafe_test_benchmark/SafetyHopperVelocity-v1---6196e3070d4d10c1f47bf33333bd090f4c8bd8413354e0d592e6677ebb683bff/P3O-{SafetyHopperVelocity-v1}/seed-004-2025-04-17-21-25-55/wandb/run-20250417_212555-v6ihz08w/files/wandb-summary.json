{"Metrics/EpLen":978.4500122070312,"Loss/Loss_reward_critic/Delta":4.105651497840881,"Train/KL":0.005888832733035088,"Loss/Loss_cost_critic":0.06521867960691452,"Time/Update":37.11968231201172,"Value/reward":102.80854797363281,"Loss/Loss_pi_cost/Delta":0,"Value/cost":0.13916432857513428,"Loss/Loss_pi_cost":0,"Metrics/EpCost":3.200000047683716,"Train/PolicyRatio/Std":0.010656553320586681,"_step":50,"Train/Epoch":49,"Train/PolicyRatio":0.9999772310256958,"Train/StopIter":10,"Time/Epoch":62.879634857177734,"Time/Rollout":25.759918212890625,"Loss/Loss_cost_critic/Delta":0.0009418576955795288,"Train/PolicyStd":0.6233327984809875,"Train/Entropy":0.9430737495422363,"Train/PolicyRatio/Max":0.9999772310256958,"Value/Adv":0.06891344487667084,"_wandb":{"runtime":3288},"Train/LR":0,"Loss/Loss_reward_critic":4.523372650146484,"Train/PolicyRatio/Min":0.9999772310256958,"Time/Total":3287.593505859375,"Metrics/EpRet":1025.2928466796875,"TotalEnvSteps":1e+06,"Time/FPS":318.0679931640625,"Loss/Loss_pi":-0.0018340934766456485,"Loss/Loss_pi/Delta":0.007110559497959912,"_runtime":3288.288786808,"_timestamp":1.744953643407615e+09}