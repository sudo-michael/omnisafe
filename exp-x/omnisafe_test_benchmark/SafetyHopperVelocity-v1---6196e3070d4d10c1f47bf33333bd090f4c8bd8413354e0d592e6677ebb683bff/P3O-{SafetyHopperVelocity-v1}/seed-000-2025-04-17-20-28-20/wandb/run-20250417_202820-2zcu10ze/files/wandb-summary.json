{"Loss/Loss_pi":-0.017004750669002533,"_timestamp":1.7449500875818796e+09,"Value/cost":-0.18922623991966248,"Time/Rollout":33.185523986816406,"Train/PolicyRatio":1.0011639595031738,"TotalEnvSteps":1e+06,"Train/PolicyRatio/Std":0.01803642511367798,"Loss/Loss_reward_critic":0.3598569929599762,"_step":50,"Time/Epoch":74.95195007324219,"Value/Adv":0.08485427498817444,"_wandb":{"runtime":3186},"Loss/Loss_pi_cost":0,"Train/LR":0,"Time/Update":41.7663688659668,"Train/PolicyRatio/Max":1.0011639595031738,"Loss/Loss_cost_critic/Delta":-0.010881546884775162,"Train/PolicyRatio/Min":1.0011639595031738,"Train/PolicyStd":0.711377739906311,"Train/KL":0.010992548428475857,"Metrics/EpLen":938.3200073242188,"Train/Entropy":1.0723797082901,"Train/Epoch":49,"_runtime":3186.889651479,"Loss/Loss_cost_critic":0.0463871955871582,"Loss/Loss_reward_critic/Delta":-0.07648703455924988,"Train/StopIter":10,"Time/Total":3186.190185546875,"Loss/Loss_pi/Delta":-0.004066667519509792,"Metrics/EpRet":1013.8123168945312,"Time/FPS":266.8376159667969,"Value/reward":100.26681518554688,"Loss/Loss_pi_cost/Delta":0,"Metrics/EpCost":20.549999237060547}