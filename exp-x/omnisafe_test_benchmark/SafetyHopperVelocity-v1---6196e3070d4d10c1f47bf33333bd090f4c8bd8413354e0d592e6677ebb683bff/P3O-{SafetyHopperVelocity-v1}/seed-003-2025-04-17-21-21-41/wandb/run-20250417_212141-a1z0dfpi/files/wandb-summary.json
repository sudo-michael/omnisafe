{"Loss/Loss_pi":-0.0017919011879712343,"Time/Epoch":87.02544403076172,"Train/KL":0.006253637373447418,"Train/LR":0,"Train/StopIter":10,"Metrics/EpRet":980.1107788085938,"Time/Rollout":40.1261100769043,"Time/Update":46.89927291870117,"Train/Entropy":1.0021473169326782,"Loss/Loss_reward_critic/Delta":-16.398079872131348,"Metrics/EpLen":953.1500244140625,"Value/cost":0.13541722297668457,"Train/PolicyRatio/Max":1.0013710260391235,"Loss/Loss_cost_critic/Delta":-0.008353274315595627,"_runtime":3707.322808524,"TotalEnvSteps":1e+06,"Train/PolicyRatio/Min":1.0013710260391235,"Value/Adv":-0.028926048427820206,"Time/Total":3706.65625,"Loss/Loss_reward_critic":8.545355796813965,"_step":50,"_wandb":{"runtime":3707},"Time/FPS":229.81785583496094,"Loss/Loss_pi/Delta":0.0012470493093132973,"Train/PolicyRatio":1.001371145248413,"Loss/Loss_pi_cost/Delta":0,"Train/Epoch":49,"Loss/Loss_pi_cost":0,"_timestamp":1.7449538091934035e+09,"Value/reward":100.57246398925781,"Train/PolicyRatio/Std":0.011588492430746555,"Loss/Loss_cost_critic":0.042140115052461624,"Train/PolicyStd":0.6594049334526062,"Metrics/EpCost":4.070000171661377}