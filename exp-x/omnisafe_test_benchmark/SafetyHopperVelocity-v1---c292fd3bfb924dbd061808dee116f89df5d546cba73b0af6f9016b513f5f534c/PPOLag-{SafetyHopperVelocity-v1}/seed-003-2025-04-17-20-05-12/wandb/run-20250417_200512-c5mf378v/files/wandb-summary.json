{"Train/PolicyRatio/Std":0.01322614774107933,"Train/Entropy":0.8965003490447998,"_timestamp":1.7449527103459117e+09,"Value/reward":39.646297454833984,"Metrics/EpLen":57.369998931884766,"Loss/Loss_cost_critic/Delta":-1.0507917404174805,"Train/PolicyRatio/Min":0.9996595978736877,"Metrics/LagrangeMultiplier/Std":0,"Train/PolicyStd":0.5990805625915527,"Loss/Loss_pi":-0.0013068851549178362,"Loss/Loss_reward_critic/Delta":-8.08673095703125,"Metrics/EpRet":88.82955932617188,"Loss/Loss_reward_critic":72.42430877685547,"Train/StopIter":40,"Value/cost":2.562638282775879,"Metrics/LagrangeMultiplier":0.31588712334632874,"Time/Epoch":158.35598754882812,"Value/Adv":0.3210966885089874,"Train/Epoch":49,"Metrics/LagrangeMultiplier/Min":0.31588712334632874,"Metrics/LagrangeMultiplier/Max":0.31588712334632874,"Loss/Loss_pi/Delta":0.0009361235424876213,"Train/PolicyRatio/Max":0.9996595978736877,"Loss/Loss_cost_critic":9.109650611877441,"_step":50,"Time/FPS":126.29772186279297,"Metrics/EpCost":2.869999885559082,"Train/PolicyRatio":0.9996595978736877,"Train/LR":0,"Time/Update":123.77767944335938,"Time/Total":7197.12353515625,"Train/KL":0.006497494876384735,"_wandb":{"runtime":7197},"Time/Rollout":34.5782470703125,"TotalEnvSteps":1e+06,"_runtime":7197.892693282}