{"Time/Epoch":164.47303771972656,"Metrics/LagrangeMultiplier/Max":0.32613351941108704,"Value/cost":3.4796788692474365,"Loss/Loss_pi":-0.002989481668919325,"Train/StopIter":40,"Metrics/EpCost":2.4000000953674316,"Metrics/LagrangeMultiplier":0.32613351941108704,"Train/KL":0.0063625662587583065,"Value/Adv":-0.08435475081205368,"Loss/Loss_pi/Delta":0.0005563800223171711,"Value/reward":48.89080047607422,"_runtime":6871.61625805,"Train/PolicyRatio":0.9993087649345398,"_wandb":{"runtime":6871},"Train/Epoch":49,"Time/FPS":121.60047912597656,"Train/PolicyRatio/Std":0.013327204622328281,"Train/Entropy":0.6916981935501099,"_timestamp":1.7449523025734875e+09,"Metrics/LagrangeMultiplier/Min":0.32613351941108704,"_step":50,"Train/PolicyRatio/Max":0.9993087649345398,"Time/Total":6870.79248046875,"Loss/Loss_reward_critic":140.1978759765625,"Loss/Loss_reward_critic/Delta":72.25697326660156,"Loss/Loss_cost_critic":10.21402359008789,"Train/PolicyStd":0.4879296123981476,"TotalEnvSteps":1e+06,"Metrics/EpLen":70.7699966430664,"Train/LR":0,"Train/PolicyRatio/Min":0.9993087649345398,"Metrics/LagrangeMultiplier/Std":0,"Time/Rollout":34.99736404418945,"Time/Update":129.47560119628906,"Metrics/EpRet":111.6360092163086,"Loss/Loss_cost_critic/Delta":4.910497188568115}