{"_step":50,"Metrics/LagrangeMultiplier/Max":0.35792118310928345,"Train/PolicyRatio":1.0013405084609985,"Train/Epoch":49,"_timestamp":1.7449503452812724e+09,"Loss/Loss_reward_critic":1.1344938278198242,"Train/KL":0.008583707734942436,"Metrics/EpCost":16.3799991607666,"Metrics/EpLen":994.239990234375,"Train/Entropy":0.8605526685714722,"Metrics/LagrangeMultiplier/Std":0,"Time/Rollout":40.413963317871094,"Metrics/LagrangeMultiplier/Min":0.35792118310928345,"Value/cost":1.2768679857254028,"Time/Total":6965.521484375,"Metrics/EpRet":1139.737060546875,"Value/Adv":0.030030056834220886,"Train/PolicyRatio/Std":0.015809690579771996,"TotalEnvSteps":1e+06,"Loss/Loss_cost_critic/Delta":0.1953689455986023,"Train/PolicyRatio/Min":1.0013405084609985,"Train/LR":0,"_runtime":6966.517297362,"Metrics/LagrangeMultiplier":0.35792118310928345,"Time/Update":135.91400146484375,"Time/Epoch":176.32801818847656,"Loss/Loss_pi":-0.008648160845041275,"Loss/Loss_cost_critic":0.6859550476074219,"Loss/Loss_pi/Delta":0.0008203526958823204,"Train/StopIter":40,"Train/PolicyStd":0.5773294568061829,"_wandb":{"runtime":6966},"Value/reward":108.74285125732422,"Train/PolicyRatio/Max":1.0013405084609985,"Time/FPS":113.42497253417969,"Loss/Loss_reward_critic/Delta":0.12604689598083496}