{"Time/Update":124.67477416992188,"Time/FPS":126.57183074951172,"_wandb":{"runtime":7459},"_step":50,"Value/Adv":0.04527192562818527,"Loss/Loss_reward_critic/Delta":2.649590492248535,"Metrics/LagrangeMultiplier/Std":0,"Time/Rollout":33.33821105957031,"Loss/Loss_cost_critic/Delta":0.69334876537323,"Train/Entropy":0.8352096080780029,"Loss/Loss_cost_critic":2.0877695083618164,"Train/Epoch":49,"Metrics/LagrangeMultiplier/Max":0.1435593217611313,"Time/Total":7458.916015625,"Train/LR":0,"Loss/Loss_pi/Delta":0.0016167438589036465,"Metrics/LagrangeMultiplier/Min":0.1435593217611313,"_timestamp":1.7449522598700113e+09,"Loss/Loss_reward_critic":8.420056343078613,"TotalEnvSteps":1e+06,"Value/cost":3.7823166847229004,"Time/Epoch":158.01304626464844,"Train/PolicyRatio/Std":0.01244084071367979,"Metrics/EpRet":1201.3629150390625,"Train/PolicyRatio":1.0008870363235474,"Train/PolicyRatio/Min":1.0008870363235474,"Metrics/LagrangeMultiplier":0.1435593217611313,"Train/PolicyRatio/Max":1.0008870363235474,"_runtime":7459.616588875,"Metrics/EpCost":49.47999954223633,"Train/StopIter":40,"Value/reward":119.96835327148438,"Train/PolicyStd":0.5618358254432678,"Train/KL":0.006337222643196583,"Metrics/EpLen":958.5399780273438,"Loss/Loss_pi":-0.005203759763389826}