wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in ./exp-x/omnisafe_test_benchmark/SafetyHalfCheetahVelocity-v1---0a95e72f354c86c49ccd39a93c0acebfb126754e8d52949a8ff62256a81ca27c/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-002-2025-04-17-22-27-39/wandb/run-20250417_222739-1a2tsmeb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-002-2025-04-17-22-27-39
wandb: â­ï¸ View project at https://wandb.ai/mlu/omnisafe
wandb: ğŸš€ View run at https://wandb.ai/mlu/omnisafe/runs/1a2tsmeb
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          Loss/Loss_cost_critic â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–†â–†â–‡â–‡â–ˆ
wandb:    Loss/Loss_cost_critic/Delta â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–…â–‚â–„â–…â–ˆâ–‚â–ƒâ–…â–ƒ
wandb:                   Loss/Loss_pi â–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–„â–…â–†â–ˆ
wandb:             Loss/Loss_pi/Delta â–â–ƒâ–â–…â–ƒâ–ƒâ–†â–„â–…â–ƒâ–…â–†â–…â–ƒâ–…â–„â–†â–…â–ƒâ–…â–…â–…â–„â–†â–„â–…â–„â–…â–…â–…â–ƒâ–ƒâ–‡â–…â–„â–†â–ˆâ–ˆâ–†â–‡
wandb:        Loss/Loss_reward_critic â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–…â–„â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–ˆâ–†
wandb:  Loss/Loss_reward_critic/Delta â–ˆâ–…â–„â–…â–„â–„â–„â–„â–„â–„â–…â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–†â–„â–†â–ƒâ–…â–„â–ƒâ–†â–„â–„â–„â–†â–„â–„â–…â–„â–ƒâ–‡â–
wandb:                 Metrics/EpCost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:                  Metrics/EpLen â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                  Metrics/EpRet â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     Metrics/LagrangeMultiplier â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–„â–†â–ˆ
wandb: Metrics/LagrangeMultiplier/Max â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–„â–†â–ˆ
wandb: Metrics/LagrangeMultiplier/Min â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–„â–†â–ˆ
wandb: Metrics/LagrangeMultiplier/Std â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                     Time/Epoch â–‡â–‡â–‡â–‡â–…â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–„â–…â–„â–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                       Time/FPS â–‚â–‚â–‚â–â–‚â–„â–„â–„â–„â–…â–„â–…â–…â–ˆâ–†â–†â–…â–‡â–‡â–…â–„â–„â–…â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–â–‚â–â–â–â–â–â–â–
wandb:                   Time/Rollout â–â–â–â–„â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–â–â–â–‚â–â–â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                     Time/Total â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    Time/Update â–‡â–‡â–‡â–ˆâ–…â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–„â–…â–ƒâ–„â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                  TotalEnvSteps â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                  Train/Entropy â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:                    Train/Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                       Train/KL â–„â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–ƒâ–
wandb:                       Train/LR â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:              Train/PolicyRatio â–…â–‡â–‚â–„â–„â–„â–†â–…â–ƒâ–†â–‡â–â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–ƒâ–†â–ƒâ–„â–„â–„â–‚â–ƒâ–â–‚â–ƒâ–„â–â–‚â–‚â–â–…â–â–ƒâ–ƒâ–…â–ƒâ–„
wandb:          Train/PolicyRatio/Max â–…â–‡â–‚â–„â–„â–„â–†â–…â–ƒâ–†â–‡â–â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–ƒâ–†â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–â–‚â–‚â–â–…â–â–ƒâ–ƒâ–…â–ƒâ–„
wandb:          Train/PolicyRatio/Min â–†â–ˆâ–ƒâ–…â–„â–…â–‡â–…â–ƒâ–‡â–ˆâ–ƒâ–‚â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–‚â–â–‚â–‚â–â–†â–â–„â–„â–†â–„â–„
wandb:          Train/PolicyRatio/Std â–…â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–ƒâ–
wandb:                Train/PolicyStd â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:                 Train/StopIter â–ˆâ–ˆâ–ˆâ–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–„â–…â–„â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                      Value/Adv â–ƒâ–‚â–ƒâ–ˆâ–„â–ƒâ–‡â–…â–‚â–ˆâ–„â–„â–„â–…â–ˆâ–ƒâ–…â–â–…â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–„
wandb:                     Value/cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–ˆ
wandb:                   Value/reward â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:          Loss/Loss_cost_critic 7.73253
wandb:    Loss/Loss_cost_critic/Delta 0.27142
wandb:                   Loss/Loss_pi -0.00585
wandb:             Loss/Loss_pi/Delta 0.00289
wandb:        Loss/Loss_reward_critic 53.52236
wandb:  Loss/Loss_reward_critic/Delta -15.72937
wandb:                 Metrics/EpCost 235.89999
wandb:                  Metrics/EpLen 1000
wandb:                  Metrics/EpRet 2162.47314
wandb:     Metrics/LagrangeMultiplier 0.26314
wandb: Metrics/LagrangeMultiplier/Max 0.26314
wandb: Metrics/LagrangeMultiplier/Min 0.26314
wandb: Metrics/LagrangeMultiplier/Std 0
wandb:                     Time/Epoch 161.19077
wandb:                       Time/FPS 124.07658
wandb:                   Time/Rollout 33.07878
wandb:                     Time/Total 5932.49854
wandb:                    Time/Update 128.11192
wandb:                  TotalEnvSteps 1000000.0
wandb:                  Train/Entropy 0.57815
wandb:                    Train/Epoch 49
wandb:                       Train/KL 0.00701
wandb:                       Train/LR 0
wandb:              Train/PolicyRatio 0.99936
wandb:          Train/PolicyRatio/Max 0.99936
wandb:          Train/PolicyRatio/Min 0.99936
wandb:          Train/PolicyRatio/Std 0.01338
wandb:                Train/PolicyStd 0.43762
wandb:                 Train/StopIter 40
wandb:                      Value/Adv -0.04164
wandb:                     Value/cost 17.88411
wandb:                   Value/reward 200.07098
wandb: 
wandb: ğŸš€ View run PPOLag-{SafetyHalfCheetahVelocity-v1}-seed-002-2025-04-17-22-27-39 at: https://wandb.ai/mlu/omnisafe/runs/1a2tsmeb
wandb: â­ï¸ View project at: https://wandb.ai/mlu/omnisafe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./exp-x/omnisafe_test_benchmark/SafetyHalfCheetahVelocity-v1---0a95e72f354c86c49ccd39a93c0acebfb126754e8d52949a8ff62256a81ca27c/PPOLag-{SafetyHalfCheetahVelocity-v1}/seed-002-2025-04-17-22-27-39/wandb/run-20250417_222739-1a2tsmeb/logs
