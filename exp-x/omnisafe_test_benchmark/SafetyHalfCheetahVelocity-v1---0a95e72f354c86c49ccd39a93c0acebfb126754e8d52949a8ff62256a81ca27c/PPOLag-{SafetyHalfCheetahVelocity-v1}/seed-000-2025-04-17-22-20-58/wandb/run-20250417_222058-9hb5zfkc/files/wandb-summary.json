{"Train/PolicyRatio/Max":1.000282645225525,"_step":50,"Train/KL":0.007365596015006304,"Value/Adv":0.08200861513614655,"Time/Rollout":32.442012786865234,"Time/FPS":126.4318618774414,"Loss/Loss_reward_critic/Delta":-2.017268180847168,"Loss/Loss_pi":-0.014250637963414192,"Train/Epoch":49,"_timestamp":1.7449594360131838e+09,"Metrics/LagrangeMultiplier/Min":0,"Metrics/LagrangeMultiplier/Std":0,"Loss/Loss_cost_critic/Delta":-0.005795549601316452,"TotalEnvSteps":1e+06,"_wandb":{"runtime":5777},"Time/Epoch":158.18797302246094,"Time/Total":5776.89697265625,"Loss/Loss_cost_critic":0.05483956262469292,"Metrics/EpLen":1000,"Value/reward":102.17862701416016,"Metrics/LagrangeMultiplier/Max":0,"Loss/Loss_reward_critic":10.514451026916504,"Train/PolicyRatio/Std":0.013617400079965591,"Train/Entropy":0.4398006796836853,"Value/cost":0.3890763819217682,"Train/PolicyStd":0.3828149139881134,"Loss/Loss_pi/Delta":0.003982970491051674,"Metrics/LagrangeMultiplier":0,"Metrics/EpCost":5.159999847412109,"_runtime":5777.601189966,"Train/PolicyRatio":1.000282645225525,"Time/Update":125.74589538574219,"Train/LR":0,"Metrics/EpRet":1100.8453369140625,"Train/StopIter":40,"Train/PolicyRatio/Min":1.000282645225525}