{"Loss/Loss_cost_critic/Delta":0.2714195251464844,"Train/PolicyRatio/Max":0.9993563294410706,"Train/KL":0.007014985661953688,"_step":50,"Train/StopIter":40,"Loss/Loss_pi":-0.00585136329755187,"Value/Adv":-0.04163619130849838,"Loss/Loss_reward_critic":53.52235794067383,"Time/Update":128.11192321777344,"Metrics/EpRet":2162.47314453125,"Train/PolicyStd":0.4376196265220642,"Metrics/LagrangeMultiplier/Max":0.2631407380104065,"Train/Epoch":49,"TotalEnvSteps":1e+06,"Value/reward":200.07098388671875,"Loss/Loss_cost_critic":7.732529163360596,"Metrics/LagrangeMultiplier/Min":0.2631407380104065,"Train/LR":0,"_runtime":5933.228962394,"Train/PolicyRatio":0.9993563294410706,"Train/Entropy":0.5781491994857788,"Time/Epoch":161.19076538085938,"Train/PolicyRatio/Min":0.9993563294410706,"Metrics/EpLen":1000,"Time/FPS":124.07658386230469,"Time/Rollout":33.07878112792969,"Train/PolicyRatio/Std":0.013378450646996498,"Metrics/LagrangeMultiplier":0.2631407380104065,"_timestamp":1.7449599926747117e+09,"Loss/Loss_pi/Delta":0.0028889519162476063,"Metrics/LagrangeMultiplier/Std":0,"Loss/Loss_reward_critic/Delta":-15.729366302490234,"Time/Total":5932.49853515625,"Value/cost":17.884111404418945,"_wandb":{"runtime":5933},"Metrics/EpCost":235.89999389648438}