{"Train/PolicyStd":0.44515690207481384,"Loss/Loss_cost_critic/Delta":0.04123961925506592,"Time/Rollout":42.2941780090332,"Train/LR":0,"Time/Epoch":176.13720703125,"Train/StopIter":40,"Metrics/EpCost":1.2300000190734863,"Metrics/LagrangeMultiplier/Max":0,"Metrics/EpLen":38.369998931884766,"Train/Epoch":49,"_step":50,"Time/Total":5965.38330078125,"Value/reward":-1.1603666543960571,"Train/PolicyRatio/Max":0.9998772144317627,"Train/KL":0.007082655094563961,"Metrics/EpRet":9.77804183959961,"Metrics/LagrangeMultiplier":0,"Loss/Loss_reward_critic":46.198219299316406,"_runtime":5966.193224872,"Value/cost":0.6645705103874207,"Metrics/LagrangeMultiplier/Min":0,"Value/Adv":-0.06749559938907623,"Train/PolicyRatio":0.9998772144317627,"Loss/Loss_reward_critic/Delta":8.914604187011719,"TotalEnvSteps":1e+06,"_wandb":{"runtime":5966},"Loss/Loss_cost_critic":1.1466529369354248,"Train/Entropy":0.6094199419021606,"Loss/Loss_pi/Delta":0.0063416603952646255,"Loss/Loss_pi":-0.015151266008615494,"Metrics/LagrangeMultiplier/Std":0,"_timestamp":1.7449433647388818e+09,"Time/FPS":113.54784393310547,"Train/PolicyRatio/Min":0.9998772144317627,"Time/Update":133.8429718017578,"Train/PolicyRatio/Std":0.012696013785898685}