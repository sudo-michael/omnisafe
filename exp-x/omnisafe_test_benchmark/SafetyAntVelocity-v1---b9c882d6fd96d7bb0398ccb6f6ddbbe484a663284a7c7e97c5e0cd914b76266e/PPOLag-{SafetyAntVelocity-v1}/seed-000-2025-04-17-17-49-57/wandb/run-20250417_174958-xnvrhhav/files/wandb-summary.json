{"Value/reward":-1.1055221557617188,"Time/FPS":104.37442779541016,"Loss/Loss_reward_critic":31.858373641967773,"Metrics/LagrangeMultiplier/Min":0,"Value/Adv":0.3540181517601013,"Loss/Loss_pi/Delta":0.004906617105007172,"Train/PolicyRatio/Std":0.013407749123871326,"Loss/Loss_cost_critic/Delta":0.015775680541992188,"TotalEnvSteps":1e+06,"Time/Rollout":47.228904724121094,"Train/PolicyRatio":0.9999198913574219,"Value/cost":0.526364266872406,"Metrics/EpLen":71.62000274658203,"Train/KL":0.007597343996167183,"Train/PolicyRatio/Max":0.9999198913574219,"_runtime":5829.803900716,"Loss/Loss_pi":-0.016727043315768242,"Time/Update":144.3888397216797,"Metrics/LagrangeMultiplier/Std":0,"Loss/Loss_cost_critic":0.7279095649719238,"_step":50,"_wandb":{"runtime":5829},"_timestamp":1.7449432281666121e+09,"Train/StopIter":40,"Metrics/EpCost":1.2300000190734863,"Train/Entropy":0.576984703540802,"Metrics/LagrangeMultiplier":0,"Loss/Loss_reward_critic/Delta":-5.630670547485352,"Time/Total":5828.8017578125,"Metrics/LagrangeMultiplier/Max":0,"Metrics/EpRet":16.430973052978516,"Train/PolicyRatio/Min":0.9999198913574219,"Train/Epoch":49,"Train/PolicyStd":0.4309111535549164,"Train/LR":0,"Time/Epoch":191.61781311035156}