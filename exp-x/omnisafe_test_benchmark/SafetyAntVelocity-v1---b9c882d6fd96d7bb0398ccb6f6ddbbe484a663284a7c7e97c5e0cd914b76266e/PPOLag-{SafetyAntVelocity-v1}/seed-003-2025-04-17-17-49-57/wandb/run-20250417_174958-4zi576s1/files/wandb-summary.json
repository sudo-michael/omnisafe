{"Metrics/LagrangeMultiplier":0,"Train/PolicyRatio":1.0005172491073608,"Train/Epoch":49,"Metrics/EpCost":0.8899999856948853,"Train/KL":0.007777988910675049,"Train/PolicyRatio/Min":1.0005172491073608,"Train/LR":0,"_timestamp":1.7449430385802143e+09,"Time/Rollout":28.14040756225586,"Train/PolicyRatio/Max":1.0005172491073608,"Value/reward":-1.8732097148895264,"Loss/Loss_reward_critic/Delta":6.8592529296875,"Loss/Loss_pi/Delta":0.004569081589579582,"Loss/Loss_cost_critic":0.7508910894393921,"Time/Total":5639.18310546875,"Loss/Loss_pi":-0.0168814267963171,"Train/Entropy":0.5975012183189392,"Value/Adv":-0.004718746989965439,"Train/PolicyRatio/Std":0.01350430864840746,"Train/PolicyStd":0.4398444890975952,"_wandb":{"runtime":5640},"TotalEnvSteps":1e+06,"Time/FPS":134.42388916015625,"_step":50,"Time/Epoch":148.78306579589844,"Metrics/LagrangeMultiplier/Std":0,"Loss/Loss_reward_critic":40.38161849975586,"Metrics/EpLen":57.90999984741211,"Metrics/LagrangeMultiplier/Min":0,"Time/Update":120.64260864257812,"Metrics/LagrangeMultiplier/Max":0,"Train/StopIter":40,"Loss/Loss_cost_critic/Delta":0.08837175369262695,"_runtime":5640.098299021,"Value/cost":0.5018028020858765,"Metrics/EpRet":13.912585258483887}