{"Time/FPS":267.5382995605469,"Loss/Loss_cost_critic":0.0779971033334732,"Loss/Loss_cost_critic/Delta":0.012320272624492645,"_runtime":3765.650569413,"Time/Epoch":74.75565338134766,"Time/Update":41.79066848754883,"Loss/Loss_pi":-0.005395913030952215,"Train/PolicyStd":0.36821532249450684,"Train/PolicyRatio/Min":1.001051902770996,"Metrics/EpRet":1072.7666015625,"Train/StopIter":10,"Train/PolicyRatio/Std":0.010822540149092674,"Value/cost":0.5539853572845459,"_step":50,"Value/reward":99.92536163330078,"Time/Rollout":32.964935302734375,"Loss/Loss_pi_cost/Delta":0,"Value/Adv":0.18824400007724762,"Train/KL":0.004741210024803877,"Train/PolicyRatio/Max":1.001051902770996,"Train/PolicyRatio":1.001051902770996,"Loss/Loss_reward_critic":8.647852897644043,"Loss/Loss_reward_critic/Delta":-0.5329627990722656,"Metrics/EpCost":7.099999904632568,"TotalEnvSteps":1e+06,"Train/LR":0,"_wandb":{"runtime":3765},"Metrics/EpLen":1000,"Train/Entropy":0.3994862139225006,"Time/Total":3764.851318359375,"_timestamp":1.7449606159217868e+09,"Loss/Loss_pi/Delta":0.0015027816407382488,"Train/Epoch":49,"Loss/Loss_pi_cost":0}