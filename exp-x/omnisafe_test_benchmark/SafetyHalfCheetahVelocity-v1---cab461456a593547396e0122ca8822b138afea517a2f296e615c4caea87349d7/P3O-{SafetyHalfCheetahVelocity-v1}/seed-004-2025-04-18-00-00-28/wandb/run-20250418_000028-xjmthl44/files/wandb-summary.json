{"Value/Adv":-0.19200582802295685,"Metrics/EpLen":1000,"Time/Total":3317.577880859375,"Loss/Loss_pi/Delta":0.0008023688569664955,"Train/PolicyStd":0.4975834786891937,"Value/reward":123.36930084228516,"_step":50,"_wandb":{"runtime":3318},"Train/PolicyRatio":0.9995051622390747,"Metrics/EpCost":19.90999984741211,"Train/PolicyRatio/Min":0.9995051622390747,"Loss/Loss_pi_cost/Delta":0,"Time/Rollout":25.789081573486328,"Train/Epoch":49,"Loss/Loss_cost_critic":0.9101345539093018,"Value/cost":1.2629207372665405,"Metrics/EpRet":1372.75537109375,"Loss/Loss_cost_critic/Delta":0.16625279188156128,"_runtime":3318.296108972,"TotalEnvSteps":1e+06,"Loss/Loss_reward_critic":50.33605194091797,"Time/FPS":312.37890625,"Train/PolicyRatio/Std":0.011097163893282413,"Loss/Loss_pi_cost":0,"Train/StopIter":10,"Train/PolicyRatio/Max":0.9995051622390747,"Train/LR":0,"_timestamp":1.7449629465268898e+09,"Loss/Loss_reward_critic/Delta":-2.3816184997558594,"Time/Update":38.23566818237305,"Train/Entropy":0.7132502198219299,"Loss/Loss_pi":-0.006169523112475872,"Time/Epoch":64.02481079101562,"Train/KL":0.0052357083186507225}