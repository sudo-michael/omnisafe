{"Loss/Loss_pi_cost/Delta":0,"Train/LR":0,"_runtime":3748.125384748,"Loss/Loss_pi":-0.004930512513965368,"Time/Rollout":33.58815002441406,"Loss/Loss_cost_critic":0.15153776109218597,"Time/Update":41.33857727050781,"Value/cost":0.8215754628181458,"TotalEnvSteps":1e+06,"Train/PolicyStd":0.38134458661079407,"Train/PolicyRatio/Min":0.9996615648269653,"Train/StopIter":10,"Train/PolicyRatio":0.9996615648269653,"Metrics/EpRet":1047.887939453125,"Time/FPS":266.92724609375,"Value/reward":97.3448715209961,"Loss/Loss_cost_critic/Delta":0.0207555890083313,"Time/Epoch":74.92678833007812,"Train/Epoch":49,"Loss/Loss_pi_cost":0,"Train/KL":0.004796605557203293,"Metrics/EpLen":1000,"Train/Entropy":0.4346226751804352,"_step":50,"Train/PolicyRatio/Std":0.010603475384414196,"Loss/Loss_reward_critic":12.847643852233887,"_timestamp":1.7449600969220428e+09,"Time/Total":3747.391845703125,"_wandb":{"runtime":3748},"Metrics/EpCost":10.880000114440918,"Loss/Loss_reward_critic/Delta":0.8617734909057617,"Loss/Loss_pi/Delta":0.0003910786472260952,"Train/PolicyRatio/Max":0.9996615648269653,"Value/Adv":0.21116551756858826}