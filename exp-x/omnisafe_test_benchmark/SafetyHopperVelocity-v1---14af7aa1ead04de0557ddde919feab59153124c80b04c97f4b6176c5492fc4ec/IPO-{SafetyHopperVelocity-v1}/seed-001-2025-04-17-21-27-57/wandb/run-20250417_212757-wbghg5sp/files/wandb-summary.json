{"Train/PolicyRatio/Max":0.999864399433136,"_step":50,"Time/Total":3566.734375,"Value/Adv":0.038563646376132965,"Train/PolicyRatio/Min":0.999864399433136,"Metrics/EpCost":28.260000228881836,"TotalEnvSteps":1e+06,"Train/KL":0.011510863900184631,"Train/Epoch":49,"Train/Entropy":1.005800724029541,"Time/Epoch":65.86770629882812,"Train/PolicyStd":0.6619939208030701,"Time/Rollout":33.785186767578125,"Train/LR":0,"Loss/Loss_reward_critic/Delta":-30.01146125793457,"Time/Update":32.08245849609375,"Value/cost":9.406840324401855,"Loss/Loss_pi/Delta":-0.0017518606036901474,"Loss/Loss_reward_critic":19.307130813598633,"Loss/Loss_cost_critic/Delta":-11.746513366699219,"Time/FPS":303.6389465332031,"Metrics/EpLen":73.5199966430664,"Train/StopIter":10,"Value/reward":21.159347534179688,"_runtime":3567.462870597,"Metrics/EpRet":161.50796508789062,"Loss/Loss_pi":-0.02470863051712513,"_timestamp":1.7449540445054698e+09,"Loss/Loss_cost_critic":9.928117752075195,"_wandb":{"runtime":3567},"Misc/Penalty":1,"Train/PolicyRatio":0.9998644590377808,"Train/PolicyRatio/Std":0.01751801371574402}