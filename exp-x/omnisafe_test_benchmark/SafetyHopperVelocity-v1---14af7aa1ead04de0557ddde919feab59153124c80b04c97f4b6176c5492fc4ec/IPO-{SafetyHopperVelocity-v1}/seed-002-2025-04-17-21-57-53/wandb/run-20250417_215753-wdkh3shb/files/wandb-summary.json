{"Train/Epoch":49,"Misc/Penalty":1,"_wandb":{"runtime":4060},"Train/LR":0,"Loss/Loss_pi/Delta":-0.03765139356255531,"Train/PolicyRatio/Min":1.0006167888641357,"Metrics/EpRet":158.08056640625,"Train/PolicyRatio":1.0006167888641357,"Loss/Loss_cost_critic/Delta":-13.420257568359375,"Train/PolicyRatio/Max":1.0006167888641357,"Time/Epoch":86.2429428100586,"Value/reward":21.27349090576172,"Train/PolicyStd":0.7378174662590027,"Train/StopIter":10,"Time/Update":37.65447235107422,"Time/FPS":231.90304565429688,"Value/Adv":-0.20700550079345703,"Loss/Loss_pi":-0.058417391031980515,"Value/cost":8.473238945007324,"Time/Total":4060.077880859375,"_runtime":4060.824979939,"Train/KL":0.011019947938621044,"Metrics/EpCost":31.3799991607666,"Loss/Loss_cost_critic":36.06352996826172,"Metrics/EpLen":75.12999725341797,"Time/Rollout":48.5883903503418,"Train/PolicyRatio/Std":0.017353693023324013,"TotalEnvSteps":1e+06,"_step":50,"_timestamp":1.7449563345207644e+09,"Train/Entropy":1.1131789684295654,"Loss/Loss_reward_critic/Delta":-31.007347106933594,"Loss/Loss_reward_critic":67.07282257080078}