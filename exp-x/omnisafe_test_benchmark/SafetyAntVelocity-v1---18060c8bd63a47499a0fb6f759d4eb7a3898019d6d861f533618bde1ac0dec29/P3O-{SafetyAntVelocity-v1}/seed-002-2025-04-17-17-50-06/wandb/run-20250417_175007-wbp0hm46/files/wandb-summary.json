{"Metrics/EpRet":71.14830017089844,"Loss/Loss_reward_critic":43.27210998535156,"_wandb":{"runtime":3869},"Time/Epoch":77.50473022460938,"Train/PolicyRatio/Min":0.999544620513916,"Value/cost":0.45377665758132935,"TotalEnvSteps":1e+06,"Time/FPS":258.04876708984375,"Loss/Loss_reward_critic/Delta":-6.267238616943359,"Loss/Loss_cost_critic/Delta":-0.14728060364723206,"Loss/Loss_pi":-0.005180359352380037,"Time/Update":43.08830642700195,"Train/StopIter":10,"Time/Total":3868.613037109375,"Train/KL":0.004262215457856655,"Loss/Loss_cost_critic":0.3579244315624237,"_timestamp":1.7449412766988544e+09,"Metrics/EpCost":1.940000057220459,"Value/reward":16.5855712890625,"Loss/Loss_pi_cost":0,"Train/PolicyRatio/Std":0.007938056252896786,"Train/PolicyStd":0.40764132142066956,"_step":50,"Metrics/EpLen":168.8800048828125,"Time/Rollout":34.416358947753906,"Train/Epoch":49,"Train/Entropy":0.5214290618896484,"Loss/Loss_pi/Delta":0.0009632287546992302,"_runtime":3869.352534447,"Value/Adv":-0.1351872831583023,"Train/LR":0,"Train/PolicyRatio":0.999544620513916,"Train/PolicyRatio/Max":0.999544620513916,"Loss/Loss_pi_cost/Delta":0}