{"Value/cost":0.5410959720611572,"_wandb":{"runtime":3870},"_timestamp":1.7449412687396328e+09,"Train/PolicyRatio/Std":0.007600498851388693,"Train/PolicyRatio/Max":1.000104546546936,"Train/PolicyStd":0.4178512394428253,"Loss/Loss_pi_cost":0,"Metrics/EpCost":1.75,"Time/Epoch":78.75003051757812,"Time/Rollout":36.54104232788086,"Train/StopIter":10,"Value/Adv":-0.24080032110214233,"Train/Entropy":0.5461320281028748,"Loss/Loss_reward_critic/Delta":5.576408386230469,"Time/Total":3869.322265625,"_runtime":3870.145684388,"Loss/Loss_cost_critic/Delta":0.063752681016922,"_step":50,"Train/PolicyRatio":1.000104546546936,"Loss/Loss_pi_cost/Delta":0,"Metrics/EpLen":125.66999816894531,"Loss/Loss_cost_critic":0.5025816559791565,"Train/Epoch":49,"Train/LR":0,"Loss/Loss_pi/Delta":0.002364861313253641,"Time/Update":42.208927154541016,"TotalEnvSteps":1e+06,"Time/FPS":253.96815490722656,"Train/KL":0.0041552078910171986,"Loss/Loss_reward_critic":51.46475601196289,"Train/PolicyRatio/Min":1.000104546546936,"Loss/Loss_pi":-0.004692603833973408,"Metrics/EpRet":42.6950798034668,"Value/reward":11.532708168029785}