{"Loss/Loss_reward_critic":56.06345748901367,"Train/PolicyStd":0.4203454256057739,"TotalEnvSteps":1e+06,"Train/PolicyRatio":1.0001784563064575,"Metrics/EpRet":45.09190368652344,"_runtime":4221.696746749,"Train/PolicyRatio/Min":1.0001784563064575,"Train/PolicyRatio/Std":0.007966415025293827,"Loss/Loss_pi_cost/Delta":0,"Train/LR":0,"Train/Epoch":49,"Train/Entropy":0.552082359790802,"Time/Epoch":77.99991607666016,"Value/reward":12.441235542297363,"Loss/Loss_reward_critic/Delta":16.57870101928711,"Loss/Loss_pi_cost":0,"Train/StopIter":10,"_timestamp":1.7449455011277544e+09,"Loss/Loss_cost_critic":0.588894784450531,"Metrics/EpLen":120.55999755859375,"Metrics/EpCost":1.5800000429153442,"Value/cost":0.7423967719078064,"Time/FPS":256.4105529785156,"_step":50,"Time/Update":41.80192565917969,"Time/Total":4220.89599609375,"Time/Rollout":36.197933197021484,"Value/Adv":-0.07668754458427429,"Loss/Loss_cost_critic/Delta":-0.08396458625793457,"Loss/Loss_pi/Delta":0.0019078520126640797,"Train/PolicyRatio/Max":1.0001784563064575,"_wandb":{"runtime":4221},"Loss/Loss_pi":-0.005079148802906275,"Train/KL":0.0042761848308146}