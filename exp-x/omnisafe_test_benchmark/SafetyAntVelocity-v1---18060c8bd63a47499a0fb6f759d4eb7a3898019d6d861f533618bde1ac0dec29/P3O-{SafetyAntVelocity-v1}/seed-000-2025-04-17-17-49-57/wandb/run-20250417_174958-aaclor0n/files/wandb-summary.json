{"Value/Adv":0.14284475147724152,"TotalEnvSteps":1e+06,"Train/Entropy":0.5278640389442444,"Train/PolicyStd":0.4102846384048462,"Time/Epoch":76.82655334472656,"Train/PolicyRatio/Min":0.9988830089569092,"Time/Total":3865.852294921875,"Train/LR":0,"Train/KL":0.0043475013226270676,"Time/Update":43.11224365234375,"Loss/Loss_reward_critic":54.24137496948242,"Loss/Loss_reward_critic/Delta":-4.805370330810547,"Loss/Loss_cost_critic":0.8312351107597351,"Loss/Loss_pi_cost":0,"Metrics/EpCost":1.7999999523162842,"_wandb":{"runtime":3866},"Value/reward":15.818951606750488,"Loss/Loss_pi":-0.005184742156416178,"Time/FPS":260.32666015625,"Loss/Loss_pi_cost/Delta":0,"Metrics/EpLen":111.47000122070312,"_step":50,"Loss/Loss_pi/Delta":0.002154767047613859,"_timestamp":1.7449412652052143e+09,"Loss/Loss_cost_critic/Delta":-0.08411985635757446,"Train/Epoch":49,"Metrics/EpRet":42.71513366699219,"Train/PolicyRatio/Std":0.008409356698393822,"Value/cost":0.7274729609489441,"Train/PolicyRatio/Max":0.9988830089569092,"Train/StopIter":10,"Time/Rollout":33.714256286621094,"_runtime":3866.717555961,"Train/PolicyRatio":0.9988830089569092}