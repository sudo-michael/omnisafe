{"Metrics/EpRet":1028.237060546875,"Train/PolicyRatio/Std":0.010199080221354961,"Train/PolicyRatio/Min":0.9999745488166809,"Metrics/EpCost":13.800000190734863,"Train/PolicyStd":0.3673449754714966,"Value/Adv":0.014625690877437592,"Loss/Loss_cost_critic/Delta":0.31522130966186523,"_timestamp":1.7449635803649297e+09,"Train/PolicyRatio":0.9999745488166809,"Train/Epoch":49,"_runtime":3592.99790915,"Loss/Loss_reward_critic":10.06265640258789,"Time/Epoch":61.06254577636719,"Time/FPS":327.53302001953125,"Value/cost":1.7146605253219604,"Value/reward":82.73600006103516,"Time/Rollout":31.025230407714844,"Loss/Loss_reward_critic/Delta":-0.31441497802734375,"Loss/Loss_pi/Delta":0.001012127846479416,"Metrics/EpLen":1000,"Misc/Penalty":0.0008928571478463709,"TotalEnvSteps":1e+06,"_step":50,"Train/KL":0.004432199522852898,"_wandb":{"runtime":3592},"Train/StopIter":10,"Train/PolicyRatio/Max":0.9999745488166809,"Time/Update":30.037254333496094,"Train/LR":0,"Loss/Loss_pi":-0.005062093958258629,"Train/Entropy":0.39931535720825195,"Time/Total":3592.1533203125,"Loss/Loss_cost_critic":5.733008861541748}