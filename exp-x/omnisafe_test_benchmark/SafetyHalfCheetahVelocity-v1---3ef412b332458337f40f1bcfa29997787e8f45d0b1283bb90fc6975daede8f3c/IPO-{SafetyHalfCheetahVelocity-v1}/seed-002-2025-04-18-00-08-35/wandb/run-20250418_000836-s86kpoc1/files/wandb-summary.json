{"Loss/Loss_reward_critic/Delta":0.4147348403930664,"Misc/Penalty":0.0011820332147181034,"Time/Update":31.871854782104492,"Value/reward":78.01443481445312,"Loss/Loss_cost_critic/Delta":0.7264938354492188,"_runtime":3579.868266356,"Train/PolicyRatio/Std":0.011398219503462315,"Metrics/EpCost":16.540000915527344,"Value/cost":2.643660545349121,"Train/PolicyRatio/Min":1.000477910041809,"Train/KL":0.004795393440872431,"Train/StopIter":10,"Time/FPS":352.66461181640625,"Metrics/EpRet":1041.22607421875,"Time/Rollout":24.83916664123535,"Loss/Loss_cost_critic":6.353389739990234,"Train/LR":0,"Train/PolicyRatio":1.0004780292510986,"Time/Total":3579.08984375,"Value/Adv":0.36040735244750977,"_wandb":{"runtime":3579},"Train/PolicyRatio/Max":1.000477910041809,"_timestamp":1.7449636957927773e+09,"Train/PolicyStd":0.37153196334838867,"Loss/Loss_pi":-0.00558085460215807,"Time/Epoch":56.71110916137695,"Train/Epoch":49,"Loss/Loss_pi/Delta":0.00179225392639637,"Train/Entropy":0.404754102230072,"Metrics/EpLen":1000,"Loss/Loss_reward_critic":6.748136520385742,"_step":50,"TotalEnvSteps":1e+06}