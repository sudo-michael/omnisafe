{"Metrics/EpLen":1000,"_step":50,"Train/PolicyRatio/Max":1.000357747077942,"Loss/Loss_pi":-0.005190260708332062,"Loss/Loss_reward_critic":47.76715087890625,"_timestamp":1.744963650820506e+09,"_wandb":{"runtime":3024},"Loss/Loss_pi/Delta":0.0021124775521457195,"TotalEnvSteps":1e+06,"Train/PolicyRatio":1.000357747077942,"Train/PolicyStd":0.4752102196216583,"Time/Epoch":48.31846237182617,"Train/PolicyRatio/Std":0.010822572745382786,"Time/FPS":413.92047119140625,"Metrics/EpRet":1293.3515625,"Time/Rollout":18.08919334411621,"Time/Update":30.229215621948242,"Metrics/EpCost":22.780000686645508,"_runtime":3024.889183132,"Train/StopIter":10,"Train/PolicyRatio/Min":1.000357747077942,"Time/Total":3024.1982421875,"Misc/Penalty":0.0045045060105621815,"Train/Epoch":49,"Train/KL":0.005409697536379099,"Loss/Loss_cost_critic":19.49376106262207,"Loss/Loss_reward_critic/Delta":1.9850425720214844,"Value/reward":83.96392822265625,"Train/Entropy":0.6684335470199585,"Value/cost":2.8539299964904785,"Value/Adv":0.041796743869781494,"Train/LR":0,"Loss/Loss_cost_critic/Delta":2.323404312133789}