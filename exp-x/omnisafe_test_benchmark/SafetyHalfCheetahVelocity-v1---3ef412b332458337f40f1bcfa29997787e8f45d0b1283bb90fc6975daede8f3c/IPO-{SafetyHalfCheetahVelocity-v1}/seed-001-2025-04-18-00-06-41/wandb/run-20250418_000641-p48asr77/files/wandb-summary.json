{"Train/PolicyRatio/Min":1.0009750127792358,"Loss/Loss_reward_critic/Delta":0.8495659828186035,"Train/PolicyRatio":1.0009750127792358,"Time/Update":31.9141788482666,"Value/reward":84.0986099243164,"_runtime":3229.795514719,"_timestamp":1.744963231508647e+09,"Time/Epoch":57.23798751831055,"Metrics/EpLen":1000,"Loss/Loss_cost_critic":8.329252243041992,"Train/PolicyRatio/Max":1.0009750127792358,"Train/Epoch":49,"Train/PolicyRatio/Std":0.015827545896172523,"Metrics/EpRet":1178.0936279296875,"Loss/Loss_cost_critic/Delta":0.8964948654174805,"Time/Total":3229.081787109375,"TotalEnvSteps":1e+06,"Loss/Loss_pi/Delta":-0.010274171363562346,"Loss/Loss_reward_critic":7.893036365509033,"Train/KL":0.0084491316229105,"Train/LR":0,"Train/PolicyStd":0.361179381608963,"Train/StopIter":10,"_wandb":{"runtime":3229},"Misc/Penalty":1,"_step":50,"Value/cost":4.978373050689697,"Train/Entropy":0.37329256534576416,"Time/FPS":349.4183044433594,"Metrics/EpCost":26.600000381469727,"Time/Rollout":25.32375717163086,"Value/Adv":-0.14728106558322906,"Loss/Loss_pi":-0.017376072704792023}