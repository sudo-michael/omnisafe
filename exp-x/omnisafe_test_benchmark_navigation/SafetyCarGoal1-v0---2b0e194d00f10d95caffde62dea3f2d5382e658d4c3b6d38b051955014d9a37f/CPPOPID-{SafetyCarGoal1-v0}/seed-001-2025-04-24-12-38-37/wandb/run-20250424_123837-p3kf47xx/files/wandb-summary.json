{"Train/PolicyRatio/Max":1.000491738319397,"Time/Update":137.528076171875,"Loss/Loss_pi/Delta":0.001088039018213749,"Time/FPS":108.88214111328125,"Metrics/EpCost":19.40999984741211,"Train/KL":0.003460923209786415,"Loss/Loss_pi":-0.012811213731765747,"Time/Total":37656.1328125,"Train/StopIter":40,"Time/Epoch":183.6848602294922,"Metrics/LagrangeMultiplier":2.368056535720825,"Loss/Loss_cost_critic/Delta":0.15069368481636047,"Train/PolicyRatio/Min":1.000491738319397,"Train/Entropy":-0.7458400130271912,"TotalEnvSteps":1e+07,"Loss/Loss_reward_critic":0.03392106294631958,"Train/PolicyRatio/Std":0.008226681500673294,"Train/Epoch":499,"_timestamp":1.745561174970364e+09,"Train/PolicyRatio":1.000491738319397,"Loss/Loss_cost_critic":0.4048665761947632,"Value/reward":1.4792661666870117,"Train/LR":0,"_wandb":{"runtime":37657},"Time/Rollout":46.156715393066406,"Metrics/EpRet":13.909832954406738,"Loss/Loss_reward_critic/Delta":0.0018947571516036987,"_step":500,"_runtime":37657.062252951,"Value/cost":2.3113932609558105,"Metrics/EpLen":1000,"Value/Adv":0.23457024991512299,"Train/PolicyStd":0.11477692425251007}