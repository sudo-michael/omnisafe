{"Train/PolicyStd":0.15535138547420502,"Time/FPS":110.87401580810547,"Train/LR":0,"Metrics/EpRet":6.718937397003174,"Metrics/EpCost":25.420000076293945,"Loss/Loss_cost_critic":0.3685099482536316,"_timestamp":1.7455639845577362e+09,"Train/KL":0.002692904556170106,"Metrics/EpLen":1000,"Train/Epoch":499,"Train/PolicyRatio":0.999956488609314,"Value/cost":2.74480938911438,"Train/PolicyRatio/Min":0.9999564290046692,"Loss/Loss_cost_critic/Delta":-0.1550726294517517,"Loss/Loss_pi":-0.014679781161248684,"Value/reward":0.9287649393081665,"Loss/Loss_pi/Delta":0.01172816101461649,"Train/Entropy":-0.46447134017944336,"Train/StopIter":40,"Train/PolicyRatio/Max":0.9999564290046692,"Metrics/LagrangeMultiplier":7.668800354003906,"Time/Total":37892.34375,"Time/Epoch":180.38491821289062,"_wandb":{"runtime":37893},"Loss/Loss_reward_critic/Delta":0.0008039306849241257,"Train/PolicyRatio/Std":0.006815335247665644,"Loss/Loss_reward_critic":0.01636362262070179,"Time/Rollout":44.29981231689453,"Time/Update":136.08505249023438,"TotalEnvSteps":1e+07,"_step":500,"_runtime":37893.180320311,"Value/Adv":0.01683618128299713}