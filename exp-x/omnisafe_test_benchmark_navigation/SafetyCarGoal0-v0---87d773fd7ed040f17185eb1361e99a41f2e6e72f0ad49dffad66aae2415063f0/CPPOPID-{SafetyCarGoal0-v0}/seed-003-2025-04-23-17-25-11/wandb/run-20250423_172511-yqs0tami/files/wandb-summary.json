{"Train/PolicyRatio/Std":0.009405242279171944,"Time/Rollout":41.252098083496094,"Metrics/EpCost":0,"Loss/Loss_reward_critic/Delta":-0.0002375766634941101,"Train/PolicyRatio":1.000507116317749,"Value/cost":-9.960641591533204e-07,"Value/reward":3.9614133834838867,"_runtime":32577.84441874,"Metrics/EpRet":38.77292251586914,"Train/LR":0,"Value/Adv":0.10304617881774902,"Train/Epoch":499,"Loss/Loss_reward_critic":0.023793168365955353,"Time/FPS":114.28173828125,"_step":500,"Loss/Loss_pi/Delta":0.004991048015654087,"Train/PolicyStd":0.030007941648364067,"Loss/Loss_cost_critic":1.3196986559105284e-10,"Train/PolicyRatio/Max":1.000507116317749,"Loss/Loss_cost_critic/Delta":5.76899639170847e-14,"Time/Total":32576.984375,"_timestamp":1.745486889439474e+09,"Time/Update":133.75392150878906,"Time/Epoch":175.00608825683594,"Train/Entropy":-2.088160514831543,"Metrics/LagrangeMultiplier":0,"Train/KL":0.003997744061052799,"TotalEnvSteps":1e+07,"Loss/Loss_pi":-0.009623542428016663,"_wandb":{"runtime":32577},"Train/PolicyRatio/Min":1.000507116317749,"Metrics/EpLen":1000,"Train/StopIter":40}