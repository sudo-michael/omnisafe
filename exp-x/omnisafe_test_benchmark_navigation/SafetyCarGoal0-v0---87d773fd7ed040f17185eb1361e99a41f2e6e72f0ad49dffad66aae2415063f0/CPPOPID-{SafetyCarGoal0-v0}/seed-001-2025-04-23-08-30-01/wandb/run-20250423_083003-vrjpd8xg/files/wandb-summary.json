{"Value/Adv":0.1274292916059494,"Train/PolicyRatio/Min":1.0001416206359863,"Train/Epoch":499,"Loss/Loss_reward_critic":0.02455560304224491,"Train/KL":0.0042854915373027325,"Train/PolicyRatio/Std":0.009653855115175247,"Loss/Loss_reward_critic/Delta":-1.0302290320396423e-05,"Train/Entropy":-2.146083116531372,"Loss/Loss_pi/Delta":0.004582680761814117,"Loss/Loss_cost_critic":1.3008247257140226e-10,"_timestamp":1.7454545603685558e+09,"_step":500,"Metrics/EpRet":39.01297378540039,"Train/LR":0,"Loss/Loss_cost_critic/Delta":1.7583157152500917e-13,"Value/cost":-6.568034677911783e-06,"Value/reward":3.9516963958740234,"Time/FPS":122.90621948242188,"Time/Total":32353.96875,"TotalEnvSteps":1e+07,"Loss/Loss_pi":-0.009621292352676392,"_runtime":32357.019624158,"Metrics/LagrangeMultiplier":0,"Metrics/EpLen":1000,"Time/Update":126.68717956542969,"Train/PolicyStd":0.028314707800745964,"Train/PolicyRatio":1.0001416206359863,"Time/Rollout":36.03846740722656,"_wandb":{"runtime":32357},"Metrics/EpCost":0,"Time/Epoch":162.7257080078125,"Train/PolicyRatio/Max":1.0001416206359863,"Train/StopIter":40}