{"Train/PolicyRatio/Max":1.000507116317749,"Loss/Loss_pi/Delta":0.004991048015654087,"Loss/Loss_reward_critic":0.023793168365955353,"Train/PolicyStd":0.030007941648364067,"Loss/Loss_pi":-0.009623542428016663,"Train/LR":0,"Metrics/LagrangeMultiplier/Max":0,"Time/Epoch":181.6715850830078,"Train/PolicyRatio/Min":1.000507116317749,"Metrics/LagrangeMultiplier":0,"Loss/Loss_cost_critic/Delta":5.76899639170847e-14,"Train/StopIter":40,"Metrics/EpCost":0,"Train/Entropy":-2.088160514831543,"Loss/Loss_reward_critic/Delta":-0.0002375766634941101,"_runtime":32925.141097973,"Loss/Loss_cost_critic":1.3196986559105284e-10,"Metrics/EpRet":38.77292251586914,"Time/Total":32921.8671875,"Value/Adv":0.10304617881774902,"_step":500,"Metrics/LagrangeMultiplier/Min":0,"_wandb":{"runtime":32925},"Train/PolicyRatio":1.000507116317749,"TotalEnvSteps":1e+07,"Train/PolicyRatio/Std":0.009405242279171944,"Value/cost":-9.960641591533204e-07,"Time/Rollout":47.170249938964844,"Time/Update":134.50128173828125,"Metrics/EpLen":1000,"Metrics/LagrangeMultiplier/Std":0,"Train/KL":0.003997744061052799,"_timestamp":1.7454551282796774e+09,"Value/reward":3.9614133834838867,"Time/FPS":110.08876037597656,"Train/Epoch":499}