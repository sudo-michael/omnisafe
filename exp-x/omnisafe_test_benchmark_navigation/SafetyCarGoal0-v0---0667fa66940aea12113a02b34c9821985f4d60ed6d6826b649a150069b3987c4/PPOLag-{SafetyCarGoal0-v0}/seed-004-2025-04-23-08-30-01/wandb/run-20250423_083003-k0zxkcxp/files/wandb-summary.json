{"Value/Adv":0.10393062233924866,"Time/Total":32109.46484375,"Value/cost":1.9332244846737012e-05,"Train/Epoch":499,"Loss/Loss_cost_critic/Delta":-2.194355808171622e-13,"Metrics/LagrangeMultiplier/Min":0,"Train/PolicyRatio":0.9998045563697815,"Metrics/EpRet":38.846397399902344,"Time/Rollout":43.41634750366211,"Time/FPS":112.76233673095703,"Train/PolicyStd":0.028526628389954567,"Metrics/LagrangeMultiplier/Max":0,"Train/PolicyRatio/Std":0.010350894182920456,"Metrics/EpLen":1000,"Value/reward":3.931217908859253,"_timestamp":1.7454543158678567e+09,"Time/Epoch":177.3641815185547,"_runtime":32112.499957487,"Loss/Loss_cost_critic":1.29602148457586e-10,"Loss/Loss_reward_critic":0.024188218638300896,"Metrics/EpCost":0,"Train/LR":0,"Train/Entropy":-2.1428606510162354,"_wandb":{"runtime":32112},"Time/Update":133.94778442382812,"Metrics/LagrangeMultiplier":0,"Metrics/LagrangeMultiplier/Std":0,"_step":500,"Train/KL":0.004493724554777145,"Train/StopIter":40,"TotalEnvSteps":1e+07,"Train/PolicyRatio/Max":0.9998044967651367,"Loss/Loss_pi":-0.010843808762729168,"Loss/Loss_pi/Delta":0.004210400395095348,"Train/PolicyRatio/Min":0.9998044967651367,"Loss/Loss_reward_critic/Delta":-0.0013839825987815857}