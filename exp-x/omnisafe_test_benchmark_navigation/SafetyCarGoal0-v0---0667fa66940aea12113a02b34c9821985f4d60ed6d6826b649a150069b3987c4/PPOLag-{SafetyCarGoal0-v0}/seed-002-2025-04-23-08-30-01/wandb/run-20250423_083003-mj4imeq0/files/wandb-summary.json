{"Loss/Loss_reward_critic/Delta":0.0022617075592279434,"Train/Epoch":499,"Train/PolicyRatio/Max":0.9999395608901978,"Train/PolicyStd":0.02995803952217102,"Train/PolicyRatio/Min":0.9999395608901978,"Metrics/LagrangeMultiplier":0,"_wandb":{"runtime":32076},"Loss/Loss_cost_critic":1.3234462137301506e-10,"Metrics/EpRet":38.71303176879883,"Train/KL":0.0043724896386265755,"Value/reward":3.9444468021392822,"Train/PolicyRatio/Std":0.009662085212767124,"Train/StopIter":40,"Time/Total":32073.8203125,"Time/Rollout":43.04486083984375,"Time/Update":135.34254455566406,"Train/PolicyRatio":0.9999395608901978,"Time/Epoch":178.38746643066406,"Loss/Loss_pi":-0.009898033924400806,"Value/cost":-2.625985189297353e-07,"TotalEnvSteps":1e+07,"Train/LR":0,"Loss/Loss_pi/Delta":0.005264776758849621,"Metrics/EpCost":0,"Metrics/EpLen":1000,"Metrics/LagrangeMultiplier/Std":0,"Value/Adv":-0.11793579161167145,"Metrics/LagrangeMultiplier/Min":0,"Loss/Loss_reward_critic":0.02451309747993946,"Train/Entropy":-2.1180622577667236,"_step":500,"Loss/Loss_cost_critic/Delta":5.155598170603071e-14,"_runtime":32076.872000818,"Time/FPS":112.1155014038086,"_timestamp":1.745454280231529e+09,"Metrics/LagrangeMultiplier/Max":0}