{"Train/PolicyRatio":1.0007890462875366,"Train/PolicyRatio/Min":1.0007890462875366,"Metrics/LagrangeMultiplier/Std":0,"Value/reward":1.6486425399780273,"Train/LR":0,"Train/Epoch":499,"Metrics/LagrangeMultiplier/Min":1.9537105560302734,"Time/Update":136.7290496826172,"Train/PolicyRatio/Max":1.0007890462875366,"Metrics/LagrangeMultiplier/Max":1.9537105560302734,"Loss/Loss_pi":-0.008958904072642326,"Time/Epoch":182.2806854248047,"Train/Entropy":-0.7542630434036255,"_wandb":{"runtime":38252},"Train/KL":0.003548277309164405,"_step":500,"Metrics/LagrangeMultiplier":1.9537105560302734,"Metrics/EpCost":19.579999923706055,"Value/Adv":-0.17369194328784943,"Loss/Loss_reward_critic/Delta":0.0017233602702617645,"Loss/Loss_cost_critic/Delta":-0.036900877952575684,"_timestamp":1.7455294022322423e+09,"Train/PolicyRatio/Std":0.00866284966468811,"TotalEnvSteps":1e+07,"Train/PolicyStd":0.11385347694158554,"Time/FPS":109.72089385986328,"Train/StopIter":40,"Loss/Loss_reward_critic":0.030394380912184715,"Time/Total":38251.921875,"Loss/Loss_cost_critic":0.2406645119190216,"Value/cost":2.0958046913146973,"Loss/Loss_pi/Delta":0.006637386977672577,"Time/Rollout":45.55157470703125,"Metrics/EpLen":1000,"_runtime":38252.722165885,"Metrics/EpRet":16.08220672607422}