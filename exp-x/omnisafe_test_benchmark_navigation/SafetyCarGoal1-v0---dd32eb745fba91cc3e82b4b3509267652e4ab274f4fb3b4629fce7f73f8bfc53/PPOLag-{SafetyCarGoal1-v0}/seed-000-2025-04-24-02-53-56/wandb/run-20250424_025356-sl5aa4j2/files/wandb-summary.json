{"Train/PolicyRatio/Std":0.008235805667936802,"Loss/Loss_reward_critic/Delta":-0.002402365207672119,"Value/reward":1.7254990339279175,"Time/Update":135.83087158203125,"Value/cost":2.4610342979431152,"Metrics/LagrangeMultiplier":5.245447635650635,"_runtime":38791.273985481,"Metrics/EpLen":1000,"Loss/Loss_reward_critic":0.03274771198630333,"Loss/Loss_cost_critic/Delta":0.03037932515144348,"Train/LR":0,"_timestamp":1.7455272278571033e+09,"Metrics/LagrangeMultiplier/Min":5.245447635650635,"Metrics/LagrangeMultiplier/Max":5.245447635650635,"Time/Total":38790.28125,"_wandb":{"runtime":38791},"Train/PolicyStd":0.1367306113243103,"Time/Rollout":43.53872299194336,"Time/FPS":111.5015869140625,"_step":500,"Loss/Loss_pi":-0.01805335097014904,"Train/KL":0.003614204004406929,"Train/Epoch":499,"Loss/Loss_pi/Delta":0.01172669604420662,"Train/PolicyRatio/Max":1.000596523284912,"Train/PolicyRatio/Min":1.000596523284912,"Loss/Loss_cost_critic":0.47157493233680725,"Metrics/EpCost":29.799999237060547,"Metrics/EpRet":16.64826011657715,"Train/StopIter":40,"Metrics/LagrangeMultiplier/Std":0,"Time/Epoch":179.36964416503906,"TotalEnvSteps":1e+07,"Train/PolicyRatio":1.000596523284912,"Train/Entropy":-0.580522358417511,"Value/Adv":0.09318434447050095}