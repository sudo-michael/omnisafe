{"Train/PolicyRatio/Std":0.0054910918697714806,"Time/Update":37.542423248291016,"Train/PolicyRatio/Max":0.9999469518661499,"Time/Total":35602.3125,"Loss/Loss_reward_critic/Delta":0.08752799034118652,"Train/Epoch":499,"_timestamp":1.7455239659871104e+09,"_wandb":{"runtime":35603},"Value/Adv":-0.27393633127212524,"TotalEnvSteps":1e+07,"_step":500,"Loss/Loss_pi":-0.002816200954839587,"Train/LR":0,"Train/PolicyRatio":0.9999469518661499,"Train/StopIter":10,"Loss/Loss_pi/Delta":0.002011252334341407,"Metrics/EpRet":37.77516174316406,"Loss/Loss_cost_critic/Delta":-2.10743922313128e-12,"Metrics/EpLen":1000,"Value/cost":-8.596058250986971e-06,"_runtime":35603.084682243,"Time/Epoch":83.27470397949219,"Train/Entropy":-1.889398217201233,"Train/KL":0.0020628124475479126,"Time/Rollout":45.732215881347656,"Train/PolicyStd":0.036695752292871475,"Loss/Loss_reward_critic":0.5977336168289185,"Metrics/EpCost":0,"Misc/Penalty":0.00039999998989515007,"Train/PolicyRatio/Min":0.9999469518661499,"Loss/Loss_cost_critic":9.639479492395964e-11,"Time/FPS":240.16897583007812,"Value/reward":-2.407604694366455}