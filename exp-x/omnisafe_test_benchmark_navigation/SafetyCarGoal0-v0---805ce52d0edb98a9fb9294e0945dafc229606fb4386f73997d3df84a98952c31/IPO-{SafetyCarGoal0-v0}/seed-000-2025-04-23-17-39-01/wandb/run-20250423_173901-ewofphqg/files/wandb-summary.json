{"Train/Entropy":-1.8710123300552368,"Time/Update":38.10475540161133,"_runtime":35995.987950658,"Train/PolicyRatio/Std":0.006478289607912302,"Metrics/EpCost":0,"Value/reward":-2.820908546447754,"Misc/Penalty":0.00039999998989515007,"Metrics/EpRet":35.65792465209961,"Train/PolicyRatio/Min":0.9995246529579163,"_step":500,"Time/FPS":229.76535034179688,"Train/KL":0.002181466668844223,"Time/Total":35994.97265625,"Train/PolicyRatio/Max":0.9995246529579163,"Value/Adv":0.13149207830429077,"Train/Epoch":499,"_timestamp":1.7454911372451077e+09,"Time/Epoch":87.04532623291016,"Loss/Loss_reward_critic/Delta":0.03752869367599487,"_wandb":{"runtime":35995},"Train/PolicyRatio":0.9995246529579163,"TotalEnvSteps":1e+07,"Loss/Loss_pi/Delta":0.001018572598695755,"Loss/Loss_cost_critic/Delta":-2.2747081995788676e-13,"Loss/Loss_reward_critic":0.6395362615585327,"Loss/Loss_cost_critic":1.2975640006906985e-10,"Time/Rollout":48.94046401977539,"Train/StopIter":10,"Loss/Loss_pi":-0.0032382234930992126,"Train/PolicyStd":0.03726474568247795,"Value/cost":6.433155249396805e-06,"Train/LR":0,"Metrics/EpLen":1000}