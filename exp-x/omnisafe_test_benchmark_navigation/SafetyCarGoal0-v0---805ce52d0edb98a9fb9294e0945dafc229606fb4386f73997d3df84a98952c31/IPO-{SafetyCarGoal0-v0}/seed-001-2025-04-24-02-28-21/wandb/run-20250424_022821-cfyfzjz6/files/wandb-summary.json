{"_step":500,"Loss/Loss_reward_critic":0.43525564670562744,"Time/Total":35161.203125,"Time/Update":34.910465240478516,"Train/PolicyRatio/Min":1.0002261400222778,"Train/Entropy":-1.6684566736221313,"Train/KL":0.0019469542894512415,"Metrics/EpRet":39.21073532104492,"Train/PolicyRatio/Std":0.005657787434756756,"Time/FPS":242.20037841796875,"Time/Rollout":47.66573715209961,"Metrics/EpLen":1000,"Loss/Loss_pi/Delta":0.0015051462687551975,"Value/cost":-1.6904134554351913e-06,"_timestamp":1.7455220636927876e+09,"Value/reward":-2.197134017944336,"Loss/Loss_cost_critic/Delta":2.227121265185872e-12,"Train/StopIter":10,"Misc/Penalty":0.00039999998989515007,"Train/PolicyRatio/Max":1.0002261400222778,"Train/PolicyRatio":1.0002261400222778,"_wandb":{"runtime":35162},"TotalEnvSteps":1e+07,"Loss/Loss_cost_critic":1.2697187745658312e-10,"Time/Epoch":82.57625579833984,"Train/LR":0,"Train/PolicyStd":0.04585111886262894,"Metrics/EpCost":0,"Loss/Loss_pi":-0.002324864733964205,"Train/Epoch":499,"Value/Adv":0.16652032732963562,"Loss/Loss_reward_critic/Delta":-0.0009962618350982666,"_runtime":35162.005147106}