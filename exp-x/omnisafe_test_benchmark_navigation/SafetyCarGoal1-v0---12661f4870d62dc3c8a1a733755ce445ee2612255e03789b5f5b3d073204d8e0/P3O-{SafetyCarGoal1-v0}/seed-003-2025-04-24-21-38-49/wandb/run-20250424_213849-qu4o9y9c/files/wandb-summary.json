{"Train/KL":0.0016881095943972468,"Loss/Loss_pi/Delta":0.000773971201851964,"Train/PolicyRatio/Std":0.005245132837444544,"Time/Epoch":90.50526428222656,"Value/Adv":0.0035868696868419647,"Time/FPS":220.98162841796875,"Time/Total":31600.931640625,"_wandb":{"runtime":31601},"Loss/Loss_reward_critic":0.007402021437883377,"Train/PolicyRatio/Min":0.9996179938316345,"Metrics/EpLen":1000,"Train/Entropy":-0.3618433177471161,"Train/Epoch":499,"Metrics/EpCost":17.549999237060547,"TotalEnvSteps":1e+07,"Train/PolicyRatio":0.9996180534362793,"Time/Rollout":47.294437408447266,"_step":500,"Loss/Loss_pi_cost/Delta":0,"Train/StopIter":10,"Loss/Loss_cost_critic":0.529572606086731,"Loss/Loss_pi":-0.0026977085508406162,"Value/cost":2.3452630043029785,"Train/PolicyRatio/Max":0.9996179938316345,"Loss/Loss_pi_cost":0,"Loss/Loss_cost_critic/Delta":-0.12168419361114502,"Train/LR":0,"Metrics/EpRet":1.4129974842071533,"Value/reward":0.1671857088804245,"_runtime":31601.635825183,"_timestamp":1.7455875309205456e+09,"Train/PolicyStd":0.18231594562530518,"Time/Update":43.21076965332031,"Loss/Loss_reward_critic/Delta":0.00039486726745963097}