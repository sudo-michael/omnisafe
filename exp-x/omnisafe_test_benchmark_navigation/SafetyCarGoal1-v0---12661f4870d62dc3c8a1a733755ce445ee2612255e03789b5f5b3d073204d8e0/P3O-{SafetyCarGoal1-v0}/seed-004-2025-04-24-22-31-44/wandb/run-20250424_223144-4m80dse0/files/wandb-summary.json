{"TotalEnvSteps":1e+07,"_wandb":{"runtime":29387},"Metrics/EpLen":1000,"Loss/Loss_pi/Delta":-0.0011013852199539542,"Train/StopIter":10,"Time/Total":29387.244140625,"Time/Epoch":87.4194564819336,"Train/LR":0,"Time/Rollout":45.0748405456543,"Train/Entropy":0.23311948776245117,"Value/cost":2.0972230434417725,"Train/Epoch":499,"Loss/Loss_cost_critic":0.5251873731613159,"Value/Adv":0.2720317840576172,"Value/reward":0.31009891629219055,"Loss/Loss_pi_cost":53.90083312988281,"_step":500,"_runtime":29387.98923121,"Metrics/EpCost":27.700000762939453,"Metrics/EpRet":1.8280847072601318,"Train/PolicyRatio/Max":1.0004222393035889,"Loss/Loss_reward_critic/Delta":0.0013048164546489716,"Time/Update":42.34455490112305,"Train/PolicyRatio":1.0004222393035889,"_timestamp":1.7455884920332263e+09,"Loss/Loss_cost_critic/Delta":-2.1190425157546997,"Loss/Loss_pi_cost/Delta":-38.538055419921875,"Train/PolicyRatio/Min":1.0004222393035889,"Train/KL":0.006839632987976074,"Loss/Loss_pi":0.0011350183049216866,"Train/PolicyRatio/Std":0.009208754636347294,"Train/PolicyStd":0.3755453824996948,"Time/FPS":228.78201293945312,"Loss/Loss_reward_critic":0.014373230747878551}