{"Time/Total":26009.72265625,"Train/Epoch":499,"Time/Update":8.853361129760742,"_timestamp":1.745555425466351e+09,"_step":500,"Train/StopIter":2,"Loss/Loss_pi/Delta":0.006578158354386687,"_runtime":26010.500702472,"Train/PolicyRatio":1.0003422498703003,"TotalEnvSteps":1e+07,"Metrics/EpCost":26.899999618530273,"Metrics/EpLen":1000,"Value/Adv":0.13868971168994904,"Loss/Loss_pi":0.0028826617635786533,"Time/FPS":336.2753601074219,"Time/Epoch":59.47507095336914,"Train/PolicyRatio/Max":1.0003422498703003,"Loss/Loss_reward_critic":0.0030393917113542557,"_wandb":{"runtime":26010},"Train/PolicyRatio/Std":0.017373861744999886,"Loss/Loss_pi_cost":37.72228240966797,"Time/Rollout":50.621429443359375,"Train/KL":0.02882431261241436,"Train/PolicyStd":0.6405859589576721,"Loss/Loss_reward_critic/Delta":0.0009423692245036364,"Train/Entropy":0.3044314682483673,"Train/LR":0,"Value/cost":3.0363450050354004,"Train/PolicyRatio/Min":1.0003422498703003,"Value/reward":-0.06984138488769531,"Loss/Loss_pi_cost/Delta":37.51527780294418,"Loss/Loss_cost_critic/Delta":1.1423126459121704,"Loss/Loss_cost_critic":1.868457555770874,"Metrics/EpRet":-0.92625892162323}