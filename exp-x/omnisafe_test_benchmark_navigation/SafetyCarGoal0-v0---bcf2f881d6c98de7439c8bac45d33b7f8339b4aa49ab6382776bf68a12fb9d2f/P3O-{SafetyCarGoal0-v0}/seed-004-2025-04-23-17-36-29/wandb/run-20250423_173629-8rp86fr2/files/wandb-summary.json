{"TotalEnvSteps":1e+07,"Train/PolicyStd":0.03237529471516609,"Loss/Loss_pi":-0.0029954793862998486,"Loss/Loss_reward_critic/Delta":-0.0028023868799209595,"Metrics/EpLen":1000,"Time/FPS":234.9007568359375,"Value/reward":3.9369616508483887,"Loss/Loss_pi_cost":0,"Value/cost":-3.4233767109981272e-06,"Train/KL":0.0020842053927481174,"Loss/Loss_pi_cost/Delta":0,"Loss/Loss_reward_critic":0.025261780247092247,"Train/Entropy":-2.0148372650146484,"Train/StopIter":10,"Train/PolicyRatio/Max":1.0000262260437012,"Time/Total":33359.96484375,"_step":500,"_timestamp":1.7454883505085597e+09,"Time/Epoch":85.14234161376953,"Metrics/EpCost":0,"Loss/Loss_cost_critic/Delta":-3.670980186498696e-12,"Train/PolicyRatio/Min":1.0000262260437012,"Train/PolicyRatio/Std":0.005817252676934004,"_runtime":33360.733764945,"Time/Rollout":39.880958557128906,"Loss/Loss_pi/Delta":0.0013631959445774555,"_wandb":{"runtime":33360},"Train/Epoch":499,"Value/Adv":-0.07737554609775543,"Time/Update":45.261322021484375,"Loss/Loss_cost_critic":1.2488489409268055e-10,"Train/LR":0,"Train/PolicyRatio":1.0000262260437012,"Metrics/EpRet":38.999691009521484}