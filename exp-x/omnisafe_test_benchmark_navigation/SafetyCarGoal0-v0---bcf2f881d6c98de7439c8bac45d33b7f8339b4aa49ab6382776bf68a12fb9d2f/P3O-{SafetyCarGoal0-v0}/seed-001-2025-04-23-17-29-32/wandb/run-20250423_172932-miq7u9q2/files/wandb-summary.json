{"Time/Total":33856.1328125,"Loss/Loss_pi_cost":0,"Value/Adv":0.1858832687139511,"Train/LR":0,"_wandb":{"runtime":33856},"Loss/Loss_pi":-0.0032458386849611998,"Loss/Loss_reward_critic/Delta":-0.00047936104238033295,"Metrics/EpLen":1000,"Train/PolicyStd":0.03629189357161522,"Loss/Loss_cost_critic":1.2908124569221968e-10,"_step":500,"_timestamp":1.745488429417907e+09,"Train/PolicyRatio":0.9996434450149536,"Time/Update":47.75593948364258,"Loss/Loss_pi/Delta":0.0013650825712829828,"Train/PolicyRatio/Min":0.9996434450149536,"Time/Rollout":45.519561767578125,"Loss/Loss_cost_critic/Delta":-1.3685858002432383e-12,"Train/StopIter":10,"Loss/Loss_pi_cost/Delta":0,"Value/reward":3.961087942123413,"Time/Epoch":93.27556610107422,"Loss/Loss_reward_critic":0.023885425180196762,"Value/cost":1.3327771739568561e-05,"Train/PolicyRatio/Max":0.9996434450149536,"Metrics/EpCost":0,"Train/Epoch":499,"Metrics/EpRet":39.31577682495117,"Train/Entropy":-1.8994691371917725,"_runtime":33856.991685764,"Train/KL":0.0025439769960939884,"Train/PolicyRatio/Std":0.006649881601333618,"Time/FPS":214.41844177246094,"TotalEnvSteps":1e+07}