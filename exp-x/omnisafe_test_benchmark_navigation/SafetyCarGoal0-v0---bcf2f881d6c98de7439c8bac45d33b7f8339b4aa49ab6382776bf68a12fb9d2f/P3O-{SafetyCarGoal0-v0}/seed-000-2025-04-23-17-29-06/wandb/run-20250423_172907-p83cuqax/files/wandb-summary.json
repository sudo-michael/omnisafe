{"Loss/Loss_cost_critic/Delta":-1.2200379595483923e-12,"Value/Adv":-0.23717351257801056,"Loss/Loss_pi_cost/Delta":0,"Loss/Loss_pi/Delta":0.002148524858057499,"Train/PolicyRatio/Max":1.0006102323532104,"Train/PolicyRatio/Std":0.0050440565682947636,"Time/FPS":256.65386962890625,"Metrics/EpRet":38.517906188964844,"Train/PolicyStd":0.035243187099695206,"Loss/Loss_pi_cost":0,"Train/PolicyRatio/Min":1.0006102323532104,"Loss/Loss_pi":-0.0024252794682979584,"Value/cost":-2.3876436898717657e-06,"Train/KL":0.001771043404005468,"Value/reward":3.8870301246643066,"TotalEnvSteps":1e+07,"Train/LR":0,"Loss/Loss_reward_critic/Delta":-0.0007458273321390152,"_step":500,"Train/Entropy":-1.9509540796279907,"_runtime":33877.48040298,"Train/Epoch":499,"Metrics/EpLen":1000,"Time/Total":33876.45703125,"Time/Rollout":37.03547286987305,"Loss/Loss_cost_critic":1.297800894528578e-10,"Time/Update":40.89043045043945,"Loss/Loss_reward_critic":0.022978225722908974,"Time/Epoch":77.92596435546875,"Metrics/EpCost":0,"_wandb":{"runtime":33877},"Train/StopIter":10,"Train/PolicyRatio":1.0006102323532104,"_timestamp":1.745488424494251e+09}