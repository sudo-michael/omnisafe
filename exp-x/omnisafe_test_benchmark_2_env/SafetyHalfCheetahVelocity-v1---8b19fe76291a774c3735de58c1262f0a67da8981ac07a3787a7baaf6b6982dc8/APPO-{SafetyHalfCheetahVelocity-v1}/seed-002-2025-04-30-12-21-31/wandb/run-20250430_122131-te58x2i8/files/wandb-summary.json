{"Train/Epoch":49,"_step":50,"Time/Epoch":297.9659729003906,"Metrics/EpRet":1430.73876953125,"Metrics/LagrangeMultiplier/Min":0.01824972592294216,"Train/LR":0,"_timestamp":1.7460548057701337e+09,"Time/Rollout":86.65914916992188,"Value/Adv":0.06334143877029419,"Train/PolicyRatio/Min":1.000065803527832,"Loss/Loss_cost_critic/Delta":-0.1894664168357849,"Time/Update":211.3067626953125,"Metrics/LagrangeMultiplier":0.01824972592294216,"Metrics/LagrangeMultiplier/Std":0,"Value/reward":126.53389739990234,"Time/Total":13913.2353515625,"Train/StopIter":80,"Train/PolicyStd":0.5044805407524109,"Train/KL":0.006521980278193951,"Train/Entropy":0.7298946976661682,"Train/PolicyRatio/Std":0.01225427445024252,"Train/PolicyRatio":1.000065803527832,"Loss/Loss_reward_critic/Delta":-0.33196258544921875,"Metrics/EpCost":31.920000076293945,"Metrics/LagrangeMultiplier/Max":0.01824972592294216,"_wandb":{"runtime":13913},"Metrics/EpLen":1000,"_runtime":13913.982630325,"Loss/Loss_cost_critic":0.7839083075523376,"TotalEnvSteps":1e+06,"Train/PolicyRatio/Max":1.000065803527832,"Loss/Loss_reward_critic":52.29927062988281,"Value/cost":2.908921718597412,"Loss/Loss_pi/Delta":0.005328229628503323,"Time/FPS":67.12175750732422,"Loss/Loss_pi":-0.013814163394272327}