{"Metrics/LagrangeMultiplier":0.013705704361200333,"Metrics/EpRet":1490.7884521484375,"Loss/Loss_cost_critic":0.6634225845336914,"Loss/Loss_reward_critic/Delta":0.2814140319824219,"Metrics/LagrangeMultiplier/Min":0.013705704361200333,"_runtime":11401.126401743,"Train/PolicyRatio/Max":0.9985798597335815,"Time/Epoch":229.64756774902344,"Metrics/LagrangeMultiplier/Max":0.013705704361200333,"Value/cost":2.7610669136047363,"Metrics/LagrangeMultiplier/Std":0,"Train/PolicyRatio":0.9985798597335815,"Train/Epoch":49,"Loss/Loss_cost_critic/Delta":-0.010846614837646484,"Train/PolicyStd":0.47621288895606995,"Time/Rollout":37.36767578125,"Loss/Loss_reward_critic":33.146759033203125,"Train/PolicyRatio/Min":0.9985798597335815,"Time/Update":192.2798309326172,"Loss/Loss_pi":-0.015305723063647747,"_wandb":{"runtime":11401},"Train/LR":0,"Value/reward":139.42550659179688,"Train/StopIter":80,"Loss/Loss_pi/Delta":0.0027037402614951134,"Time/FPS":87.08997344970703,"TotalEnvSteps":1e+06,"Metrics/EpCost":30.739999771118164,"Value/Adv":0.11104283481836319,"Train/KL":0.0070722270756959915,"Train/Entropy":0.6699978709220886,"Metrics/EpLen":1000,"Time/Total":11400.3017578125,"_step":50,"_timestamp":1.7460554849369252e+09,"Train/PolicyRatio/Std":0.01316835731267929}