{"Metrics/EpRet":1430.2197265625,"Value/cost":3.3632843494415283,"Value/Adv":0.17257995903491974,"Train/PolicyRatio/Std":0.013058807700872421,"Train/PolicyRatio":0.9991618394851685,"_runtime":12448.312493688,"Loss/Loss_pi/Delta":0.0021066945046186447,"Time/Rollout":67.01309967041016,"Time/Epoch":265.8609619140625,"Train/PolicyStd":0.41927751898765564,"TotalEnvSteps":1e+06,"Loss/Loss_reward_critic":38.73991012573242,"Train/LR":0,"Train/StopIter":80,"Train/KL":0.007225444074720144,"Time/Update":198.84776306152344,"Metrics/EpLen":1000,"Loss/Loss_pi":-0.013223913498222828,"Train/Entropy":0.5345523953437805,"Metrics/LagrangeMultiplier/Min":0.0028225756250321865,"Train/PolicyRatio/Max":0.9991617798805237,"Loss/Loss_cost_critic":0.559495747089386,"Metrics/LagrangeMultiplier/Std":0,"_wandb":{"runtime":12448},"Metrics/LagrangeMultiplier/Max":0.0028225756250321865,"_step":50,"Train/Epoch":49,"Metrics/LagrangeMultiplier":0.0028225756250321865,"Train/PolicyRatio/Min":0.9991617798805237,"Time/FPS":75.227294921875,"Loss/Loss_cost_critic/Delta":0.050288498401641846,"Loss/Loss_reward_critic/Delta":-4.403186798095703,"Metrics/EpCost":32.31999969482422,"_timestamp":1.746056713835257e+09,"Value/reward":135.8016815185547,"Time/Total":12447.5947265625}