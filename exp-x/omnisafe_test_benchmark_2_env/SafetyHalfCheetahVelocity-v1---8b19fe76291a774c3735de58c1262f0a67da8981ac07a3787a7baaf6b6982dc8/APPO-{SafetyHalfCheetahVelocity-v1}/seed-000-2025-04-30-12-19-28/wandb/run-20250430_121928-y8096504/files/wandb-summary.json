{"Time/FPS":56.17039108276367,"Time/Epoch":356.0594787597656,"Value/cost":3.026299238204956,"Loss/Loss_reward_critic/Delta":-0.2840538024902344,"_runtime":13296.320265088,"Train/PolicyRatio/Std":0.015148967504501343,"Loss/Loss_cost_critic":0.9780093431472778,"Metrics/LagrangeMultiplier":0.007649299688637257,"Loss/Loss_pi":-0.01762523502111435,"Metrics/LagrangeMultiplier/Min":0.007649299688637257,"Value/reward":125.8331527709961,"Train/PolicyRatio/Min":0.9997294545173645,"TotalEnvSteps":1e+06,"Train/PolicyRatio/Max":0.9997294545173645,"Metrics/LagrangeMultiplier/Std":0,"_wandb":{"runtime":13296},"_timestamp":1.7460540647550378e+09,"Train/Epoch":49,"Loss/Loss_pi/Delta":0.005171887576580048,"Train/LR":0,"Time/Rollout":119.75627899169922,"Value/Adv":-0.05479086935520172,"Metrics/EpCost":24.420000076293945,"Metrics/LagrangeMultiplier/Max":0.007649299688637257,"Metrics/EpLen":1000,"Train/KL":0.009755350649356842,"Train/Entropy":0.5695194602012634,"Time/Update":236.30311584472656,"Loss/Loss_reward_critic":46.50725173950195,"Train/StopIter":80,"Train/PolicyRatio":0.9997295141220093,"Loss/Loss_cost_critic/Delta":0.29980379343032837,"Time/Total":13295.56640625,"Metrics/EpRet":1314.5137939453125,"_step":50,"Train/PolicyStd":0.43397048115730286}