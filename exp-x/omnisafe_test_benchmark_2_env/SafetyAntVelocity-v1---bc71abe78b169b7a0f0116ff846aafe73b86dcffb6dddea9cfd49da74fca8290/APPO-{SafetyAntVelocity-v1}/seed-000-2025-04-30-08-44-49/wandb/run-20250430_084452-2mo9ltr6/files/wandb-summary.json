{"_step":50,"Train/PolicyRatio":1.0014580488204956,"Metrics/LagrangeMultiplier":0,"Loss/Loss_reward_critic/Delta":-3.766633987426758,"_runtime":12874.972517089,"Time/FPS":54.80485534667969,"_timestamp":1.7460407671749296e+09,"Value/reward":-0.41011863946914673,"Loss/Loss_pi/Delta":0.006600098684430122,"_wandb":{"runtime":12874},"Value/cost":0.3824256956577301,"Metrics/LagrangeMultiplier/Min":0,"Train/Epoch":49,"Time/Update":240.9888916015625,"Train/LR":0,"Loss/Loss_pi":-0.023092297837138176,"Loss/Loss_reward_critic":29.903993606567383,"Metrics/EpRet":35.78937911987305,"Loss/Loss_cost_critic":0.5790237188339233,"Time/Epoch":364.93115234375,"Metrics/LagrangeMultiplier/Std":0,"Train/PolicyRatio/Std":0.014963646419346333,"Train/StopIter":80,"Loss/Loss_cost_critic/Delta":-0.08928602933883667,"Train/PolicyRatio/Max":1.0014580488204956,"Train/Entropy":0.5586049556732178,"Value/Adv":-0.06990445405244827,"Metrics/EpLen":132.3699951171875,"Metrics/EpCost":1.9800000190734863,"Train/PolicyRatio/Min":1.0014580488204956,"Train/KL":0.009585101157426834,"TotalEnvSteps":1e+06,"Time/Total":12871.896484375,"Metrics/LagrangeMultiplier/Max":0,"Train/PolicyStd":0.4230712056159973,"Time/Rollout":123.94220733642578}