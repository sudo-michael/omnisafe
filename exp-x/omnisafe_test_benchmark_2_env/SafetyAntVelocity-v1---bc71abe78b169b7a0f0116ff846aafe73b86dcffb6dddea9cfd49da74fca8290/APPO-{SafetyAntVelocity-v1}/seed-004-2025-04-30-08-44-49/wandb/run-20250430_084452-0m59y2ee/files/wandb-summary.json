{"_wandb":{"runtime":12857},"Loss/Loss_reward_critic":35.538326263427734,"Train/PolicyRatio/Min":1.0004273653030396,"Time/Rollout":123.64649963378906,"Loss/Loss_cost_critic/Delta":-0.08417493104934692,"Loss/Loss_reward_critic/Delta":-2.8538894653320312,"Train/KL":0.00978707056492567,"Train/Entropy":0.5833306312561035,"Metrics/EpLen":72.41000366210938,"Time/Total":12854.7294921875,"_runtime":12857.795483007,"_step":50,"Loss/Loss_pi":-0.024069769307971,"Metrics/LagrangeMultiplier/Std":0,"Train/PolicyRatio/Std":0.014633954502642155,"Metrics/LagrangeMultiplier/Max":0,"Metrics/LagrangeMultiplier/Min":0,"Time/FPS":55.4188346862793,"Value/Adv":0.0679868534207344,"Time/Update":237.24156188964844,"Metrics/EpCost":1.149999976158142,"Train/Epoch":49,"Loss/Loss_pi/Delta":0.006673220545053482,"Train/PolicyRatio":1.000427484512329,"_timestamp":1.746040749991941e+09,"Train/PolicyRatio/Max":1.0004273653030396,"TotalEnvSteps":1e+06,"Value/cost":0.5748748779296875,"Loss/Loss_cost_critic":0.693483293056488,"Metrics/LagrangeMultiplier":0,"Train/StopIter":80,"Train/LR":0,"Train/PolicyStd":0.4337850511074066,"Metrics/EpRet":21.900190353393555,"Time/Epoch":360.8881530761719,"Value/reward":-0.772304117679596}