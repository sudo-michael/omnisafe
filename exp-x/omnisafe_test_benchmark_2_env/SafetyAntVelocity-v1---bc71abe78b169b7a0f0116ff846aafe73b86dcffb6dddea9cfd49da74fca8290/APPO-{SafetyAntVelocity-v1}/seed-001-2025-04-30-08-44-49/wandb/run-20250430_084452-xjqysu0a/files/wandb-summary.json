{"Loss/Loss_pi/Delta":0.008225006982684135,"Train/Entropy":0.5823746919631958,"Metrics/EpLen":76.81999969482422,"Loss/Loss_reward_critic":36.183387756347656,"Value/cost":0.48220664262771606,"Loss/Loss_cost_critic":0.627074122428894,"Train/StopIter":80,"Train/PolicyRatio":0.9996734857559204,"Train/LR":0,"Train/PolicyRatio/Min":0.9996734857559204,"Metrics/LagrangeMultiplier/Std":0,"Metrics/LagrangeMultiplier/Min":0,"Train/PolicyRatio/Std":0.014548048377037048,"Value/Adv":-0.025878652930259705,"_wandb":{"runtime":12998},"Time/Total":12995.6259765625,"Time/FPS":55.33397674560547,"Metrics/LagrangeMultiplier/Max":0,"Time/Update":235.55734252929688,"Train/PolicyStd":0.4332357347011566,"Loss/Loss_cost_critic/Delta":0.23880136013031006,"Metrics/EpRet":19.679370880126953,"Train/Epoch":49,"Loss/Loss_pi":-0.022445207461714745,"Time/Epoch":361.44158935546875,"_step":50,"_timestamp":1.7460408908907561e+09,"TotalEnvSteps":1e+06,"Loss/Loss_reward_critic/Delta":2.6987991333007812,"_runtime":12998.755780281,"Value/reward":-1.6134611368179321,"Metrics/EpCost":1.1799999475479126,"Train/PolicyRatio/Max":0.9996734857559204,"Train/KL":0.009113512933254242,"Metrics/LagrangeMultiplier":0,"Time/Rollout":125.8841781616211}