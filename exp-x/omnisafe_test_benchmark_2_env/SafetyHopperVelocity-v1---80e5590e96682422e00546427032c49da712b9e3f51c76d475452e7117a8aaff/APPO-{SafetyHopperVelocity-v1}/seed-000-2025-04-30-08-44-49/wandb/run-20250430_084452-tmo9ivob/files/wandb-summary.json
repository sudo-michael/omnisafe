{"Value/Adv":0.08955054730176926,"_wandb":{"runtime":16372},"Train/PolicyRatio":1.000166893005371,"Train/StopIter":80,"Time/Update":234.71051025390625,"_step":50,"Metrics/EpLen":940.3200073242188,"_runtime":16372.490229277,"Time/Total":16369.412109375,"Metrics/EpCost":12.130000114440918,"Train/Entropy":0.9306021928787231,"Loss/Loss_reward_critic/Delta":1.3718230724334717,"Train/KL":0.009877610020339489,"Train/PolicyStd":0.6168416142463684,"TotalEnvSteps":1e+06,"Train/LR":0,"Train/PolicyRatio/Std":0.015905821695923805,"Loss/Loss_cost_critic":0.7497458457946777,"Metrics/LagrangeMultiplier":0.32641518115997314,"Loss/Loss_cost_critic/Delta":0.3244737684726715,"Train/PolicyRatio/Max":1.000166893005371,"Time/Epoch":355.6506042480469,"Time/Rollout":120.94004821777344,"_timestamp":1.7460442646924877e+09,"Metrics/LagrangeMultiplier/Max":0.32641518115997314,"Train/Epoch":49,"Time/FPS":56.23496627807617,"Loss/Loss_reward_critic":4.690780162811279,"Loss/Loss_pi/Delta":0.002385152503848076,"Train/PolicyRatio/Min":1.000166893005371,"Loss/Loss_pi":-0.0073716240003705025,"Value/reward":118.96183776855469,"Metrics/LagrangeMultiplier/Std":0,"Metrics/EpRet":1133.871337890625,"Value/cost":2.2055366039276123,"Metrics/LagrangeMultiplier/Min":0.32641518115997314}