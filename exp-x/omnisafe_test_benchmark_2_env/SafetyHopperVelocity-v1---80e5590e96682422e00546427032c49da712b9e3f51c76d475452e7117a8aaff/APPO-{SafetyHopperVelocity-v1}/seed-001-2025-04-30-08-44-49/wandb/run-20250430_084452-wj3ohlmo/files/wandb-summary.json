{"TotalEnvSteps":1e+06,"Loss/Loss_cost_critic/Delta":-0.03694218397140503,"Train/KL":0.012545088306069374,"Time/Epoch":387.79425048828125,"_step":50,"_runtime":16662.876465217,"Value/reward":145.9846954345703,"Time/FPS":51.57373809814453,"Metrics/EpLen":982.9600219726562,"Train/PolicyRatio/Max":1.0008900165557861,"Loss/Loss_pi":-0.016499631106853485,"Train/Epoch":49,"Train/PolicyRatio/Std":0.018816448748111725,"Loss/Loss_pi/Delta":-0.006872066296637058,"Train/StopIter":80,"Metrics/EpRet":1468.6331787109375,"Loss/Loss_cost_critic":0.3458159565925598,"Loss/Loss_reward_critic/Delta":-0.1282869577407837,"Train/PolicyRatio/Min":1.0008900165557861,"Metrics/LagrangeMultiplier/Min":0.332698792219162,"Train/PolicyStd":0.5577735304832458,"Train/PolicyRatio":1.0008900165557861,"_wandb":{"runtime":16662},"Train/LR":0,"_timestamp":1.7460445550717218e+09,"Value/Adv":0.11673258244991302,"Metrics/LagrangeMultiplier":0.332698792219162,"Loss/Loss_reward_critic":0.8311854004859924,"Time/Rollout":124.85479736328125,"Time/Update":262.93939208984375,"Train/Entropy":0.8276728987693787,"Metrics/EpCost":21.40999984741211,"Value/cost":2.845860004425049,"Metrics/LagrangeMultiplier/Std":0,"Time/Total":16659.783203125,"Metrics/LagrangeMultiplier/Max":0.332698792219162}