{"Train/StopIter":40,"Train/PolicyRatio/Max":0.9998259544372559,"Time/FPS":107.8581771850586,"Loss/Loss_pi/Delta":0.006400110200047493,"Metrics/EpCost":143.1199951171875,"Train/PolicyRatio/Std":0.011649529449641705,"Loss/Loss_pi":-0.015846969559788704,"Value/reward":1.9479658603668213,"Train/PolicyRatio/Min":0.9998259544372559,"Time/Epoch":185.42869567871094,"Train/PolicyStd":0.3506771922111511,"Loss/Loss_reward_critic":0.06326288729906082,"Train/Entropy":0.36624595522880554,"Value/Adv":-0.06315715610980988,"Train/KL":0.006111584138125181,"Loss/Loss_reward_critic/Delta":0.012172259390354156,"_runtime":7302.724234528,"Metrics/EpRet":17.736473083496094,"Metrics/EpLen":1000,"Time/Total":7301.95458984375,"Time/Rollout":105.33499908447266,"_step":50,"Train/Epoch":49,"_wandb":{"runtime":7302},"TotalEnvSteps":1e+06,"Train/LR":0,"Time/Update":80.0936279296875,"_timestamp":1.7466193223897383e+09,"Train/PolicyRatio":0.9998259544372559}